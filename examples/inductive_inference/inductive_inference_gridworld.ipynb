{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conor/Documents/ml_at_verses/pymdp_dev/pymdp/pymdp/agent.py:706: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (\n"
     ]
    }
   ],
   "source": [
    "import jax.tree_util as jtu\n",
    "from jax import numpy as jnp, random as jr\n",
    "from jax import nn, vmap\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pymdp.legacy.envs import GridWorldEnv\n",
    "from pymdp import control\n",
    "from pymdp.agent import Agent as AIFAgent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid world generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_columns = 7, 7\n",
    "num_states = [num_rows*num_columns] # number of states equals the number of grid locations\n",
    "num_obs = [num_rows*num_columns]    # number of observations equals the number of grid locations (fully observable)\n",
    "\n",
    "# number of agents\n",
    "n_batches = 5\n",
    "\n",
    "# construct A arrays\n",
    "A = [jnp.broadcast_to(jnp.eye(num_states[0]), (n_batches,) + (num_obs[0], num_states[0]))] # fully observable (identity observation matrix\n",
    "\n",
    "# construct B arrays\n",
    "grid_world = GridWorldEnv(shape=[num_rows, num_columns])\n",
    "B = [jnp.broadcast_to(jnp.array(grid_world.get_transition_dist()), (n_batches,) + (num_states[0], num_states[0], grid_world.n_control))]  # easy way to get the generative model parameters is to extract them from one of pre-made GridWorldEnv classes\n",
    "num_controls = [grid_world.n_control] # number of control states equals the number of actions\n",
    " \n",
    "# create mapping from gridworld coordinates to linearly-index states\n",
    "grid = np.arange(grid_world.n_states).reshape(grid_world.shape)\n",
    "it = np.nditer(grid, flags=[\"multi_index\"])\n",
    "coord_to_idx_map = {}\n",
    "while not it.finished:\n",
    "    coord_to_idx_map[it.multi_index] = it.iterindex\n",
    "    it.iternext()\n",
    "\n",
    "# construct C arrays\n",
    "desired_position = (6,6) # lower corner\n",
    "desired_state_id = coord_to_idx_map[desired_position]\n",
    "desired_obs_id = jnp.argmax(A[0][:, desired_state_id]) # throw this in there, in case there is some indeterminism between states and observations\n",
    "C = [jnp.broadcast_to(nn.one_hot(desired_obs_id, num_obs[0]), (n_batches, num_obs[0]))]\n",
    "\n",
    "# construct D arrays\n",
    "starting_position = (3, 3) # middle\n",
    "# starting_position = (0, 0) # upper left corner\n",
    "starting_state_id = coord_to_idx_map[starting_position]\n",
    "starting_obs_id = jnp.argmax(A[0][:, starting_state_id]) # throw this in there, in case there is some indeterminism between states and observations\n",
    "D = [jnp.broadcast_to(nn.one_hot(starting_state_id, num_states[0]), (n_batches, num_states[0]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_horizon, inductive_threshold = 1, 0.1\n",
    "inductive_depth = 7\n",
    "policy_matrix = control.construct_policies(num_states, num_controls, policy_len=planning_horizon)\n",
    "\n",
    "# inductive planning goal states\n",
    "H = [jnp.broadcast_to(nn.one_hot(desired_state_id, num_states[0]), (n_batches, num_states[0]))] # list of factor-specific goal vectors (shape of each is (n_batches, num_states[f]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize an `Agent()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create agent\n",
    "agent = AIFAgent(A, B, C, D, E=None, pA=None, pB=None, batch_size=n_batches, policies=policy_matrix, policy_len=planning_horizon, \n",
    "                inductive_depth=inductive_depth, inductive_threshold=inductive_threshold,\n",
    "                H=H, use_utility=True, use_states_info_gain=False, use_param_info_gain=False, use_inductive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run active inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid position for agent 2 at time 0: (np.int64(3), np.int64(3))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-04 18:30:17.612952: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid position for agent 2 at time 1: (np.int64(3), np.int64(4))\n",
      "Grid position for agent 2 at time 2: (np.int64(3), np.int64(5))\n",
      "Grid position for agent 2 at time 3: (np.int64(3), np.int64(6))\n",
      "Grid position for agent 2 at time 4: (np.int64(4), np.int64(6))\n",
      "Grid position for agent 2 at time 5: (np.int64(5), np.int64(6))\n",
      "Grid position for agent 2 at time 6: (np.int64(6), np.int64(6))\n"
     ]
    }
   ],
   "source": [
    "# T = 14 # needed if you start further away from the goal (e.g. in upper left corner)\n",
    "T = 7 # can get away with fewer timesteps if you start closer to the goal (e.g. in the middle)\n",
    "\n",
    "qs_init = [jnp.broadcast_to(nn.one_hot(starting_state_id, num_states[0]), (n_batches, num_states[0]))] # same as D\n",
    "obs_idx = [jnp.broadcast_to(starting_obs_id, (n_batches,))] # list of len (num_modalities), each list element of shape (n_batches,)\n",
    "obs_idx  = jtu.tree_map(lambda x: jnp.expand_dims(x, -1), obs_idx) #  list of len (num_modalities), elements each of shape (n_batches,1), this adds a trivial \"time dimension\"\n",
    "\n",
    "state = jnp.broadcast_to(starting_state_id, (n_batches,))\n",
    "empirical_prior = agent.D\n",
    "batch_keys = jr.split(jr.PRNGKey(0), n_batches)\n",
    "batch_to_track = 1\n",
    "actions_t = None\n",
    "\n",
    "for t in range(T):\n",
    "\n",
    "    print('Grid position for agent {} at time {}: {}'.format(batch_to_track+1, t, np.unravel_index(state[batch_to_track], grid_world.shape)))\n",
    "\n",
    "    beliefs = agent.infer_states(obs_idx, empirical_prior=empirical_prior)\n",
    "    q_pi, _ = agent.infer_policies(beliefs)\n",
    "    actions_t = agent.sample_action(q_pi, rng_key=batch_keys)\n",
    "    empirical_prior, qs_t = agent.update_empirical_prior(actions_t, beliefs)\n",
    "\n",
    "    # get next state and observation from the grid world (need to vmap everything over batches)\n",
    "    state = vmap(lambda b, s, a: jnp.argmax(b[:, s, a]), in_axes=(0,0,0))(B[0], state, actions_t)\n",
    "    next_obs = vmap(lambda a, s: jnp.argmax(a[:, s]), in_axes=(0,0))(A[0], state)\n",
    "    obs_idx = [next_obs]\n",
    "    obs_idx  = jtu.tree_map(lambda x: jnp.expand_dims(x, -1), obs_idx) # add a trivial time dimension to the observation to enable indexing during agent.infer_states"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymdp_dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
