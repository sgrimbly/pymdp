{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Inference Demo: Epistemic Chaining\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/infer-actively/pymdp/blob/master/docs/notebooks/cue_chaining_demo.ipynb)\n",
    "\n",
    "*Author: Conor Heins*\n",
    "\n",
    "This demo notebook builds a generative model from scratch, constructs an `Agent` instance using the constructed generative model, and then runs an active inference simulation in a simple environment.\n",
    "\n",
    "The environment used here is similar in spirit to the [T-Maze demo](https://pymdp-rtd.readthedocs.io/en/latest/notebooks/tmaze_demo.html), but the task structure is more complex. Here, we analogize the agent to a rat tasked with solving a spatial puzzle. The rat must sequentially visit a sequence of two cues located at different locations in a 2-D grid world, in order to ultimately reveal the locations of two (opposite) reward outcomes: one location will give the rat a reward (\"Cheese\") and the other location will give the rat a punishment (\"Shock\").\n",
    "\n",
    "Using active inference to solve a POMDP representation of this task, the rat can successfully forage the correct cues in sequence, in order to ultimately discover the location of the \"Cheese\", and avoid the \"Shock\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: When running this notebook in Google Colab, you may have to run `!pip install inferactively-pymdp` at the top of the notebook, before you can `import pymdp`. That cell is left commented out below, in case you are running this notebook from Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install inferactively-pymdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "from pymdp.agent import Agent\n",
    "from pymdp import utils, maths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid World Parameters\n",
    "Let's begin by initializing several variables related to the physical environment inhabited by the agent. These variables will encode things like the dimensions of the grid, the possible locations of the different cues, and the possible locations of the reward or punishment.\n",
    "\n",
    "Having these variables defined will also come in handy when setting up the generative model of our agent and when creating the environment class.\n",
    "\n",
    "We will create a grid world with dimensions $5 \\times 7$. Particular locations of the grid are indexed as (y, x) tuples, that select a particular row and column respectively of that location in the grid.\n",
    "\n",
    "By design of the task, one location in the grid world contain a cue: **Cue 1**. There will be four additional locations, that will serve as possible locations for a second cue: **Cue 2**. Crucially, only *one* of these four additional locations will actually contain **Cue 2** - the other 3 will be empty. When the agent visits **Cue 1** by moving to its location, one of four signals is presented, which each unambiguously signal which of the 4 possible locations **Cue 2** occupies -- we can refer to these Cue-2-location-signals with obvious names: `L1`, `L2`, `L3`, `L4`. Once **Cue 2**'s location has been revealed, by visiting that location the agent will then receive one of two possible signals, that indicate where the hidden reward is located (and conversely, where the hidden punishment lies). These two possible reward/punishment locations are indicated by two locations: \"TOP\" (meaning the \"Cheese\" reward is on the upper of the two locations) or \"BOTTOM\" (meaning the \"Cheese\" reward is on the lower of the two locations).\n",
    "\n",
    "In this way, the most efficient and risk-sensitive way to achieve reward in this task is to first visit **Cue 1**, in order to figure out the location of **Cue 2**, in order to figure out the location of the reward.\n",
    "\n",
    "*Tip*: When setting up `pymdp` generative models and task environments, we recommend creating additional variables, like lists of strings or dicts with string-valued keys, that help you relate the values of various aspects of the task to semantically-meaning labels. These come in handy when generating print statements during debugging or labels for plotting. For example, below we create a list called `reward_conditions` that stores the \"names\" of the two reward conditions: `\"TOP\"` and `\"BOTTOM\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dims = [5, 7] # dimensions of the grid (number of rows, number of columns)\n",
    "num_grid_points = np.prod(grid_dims) # total number of grid locations (rows X columns)\n",
    "\n",
    "# create a look-up table `loc_list` that maps linear indices to tuples of (y, x) coordinates \n",
    "grid = np.arange(num_grid_points).reshape(grid_dims)\n",
    "it = np.nditer(grid, flags=[\"multi_index\"])\n",
    "\n",
    "loc_list = []\n",
    "while not it.finished:\n",
    "    loc_list.append(it.multi_index)\n",
    "    it.iternext()\n",
    "\n",
    "# (y, x) coordinate of the first cue's location, and then a list of the (y, x) coordinates of the possible locations of the second cue, and their labels (`L1`, `L2`, ...)\n",
    "cue1_location = (2, 0)\n",
    "\n",
    "cue2_loc_names = ['L1', 'L2', 'L3', 'L4']\n",
    "cue2_locations = [(0, 2), (1, 3), (3, 3), (4, 2)]\n",
    "\n",
    "# names of the reward conditions and their locations\n",
    "reward_conditions = [\"TOP\", \"BOTTOM\"]\n",
    "reward_locations = [(1, 5), (3, 5)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the grid world\n",
    "\n",
    "Let's quickly use the variables we just defined to visualize the grid world, including the **Cue 1** location, the possible **Cue 2** locations, and the possible reward locations (in gray, since we don't know which one has the \"Cheese\" and which one has the \"Shock\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6)) \n",
    "\n",
    "# create the grid visualization\n",
    "X, Y = np.meshgrid(np.arange(grid_dims[1]+1), np.arange(grid_dims[0]+1))\n",
    "h = ax.pcolormesh(X, Y, np.ones(grid_dims), edgecolors='k', vmin = 0, vmax = 30, linewidth=3, cmap = 'coolwarm')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Put gray boxes around the possible reward locations\n",
    "reward_top = ax.add_patch(patches.Rectangle((reward_locations[0][1],reward_locations[0][0]),1.0,1.0,linewidth=5,edgecolor=[0.5, 0.5, 0.5],facecolor=[0.5, 0.5, 0.5]))\n",
    "reward_bottom = ax.add_patch(patches.Rectangle((reward_locations[1][1],reward_locations[1][0]),1.0,1.0,linewidth=5,edgecolor=[0.5, 0.5, 0.5],facecolor=[0.5, 0.5, 0.5]))\n",
    "\n",
    "text_offsets = [0.4, 0.6]\n",
    "\n",
    "cue_grid = np.ones(grid_dims)\n",
    "cue_grid[cue1_location[0],cue1_location[1]] = 15.0\n",
    "for ii, loc_ii in enumerate(cue2_locations):\n",
    "  row_coord, column_coord = loc_ii\n",
    "  cue_grid[row_coord, column_coord] = 5.0\n",
    "  ax.text(column_coord+text_offsets[0], row_coord+text_offsets[1], cue2_loc_names[ii], fontsize = 15, color='k')\n",
    "h.set_array(cue_grid.ravel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative model\n",
    "\n",
    "The hidden states $\\mathbf{s}$ of the generative model are factorized into three hidden states factors:\n",
    "\n",
    "1. a **Location** hidden state factor with as many levels as there are grid locations. This encodes the agent's location in the grid world.\n",
    "2. a **Cue 2 Location** hidden state factor with 4 levels -- this encodes in which of the four possible locations **Cue 2** is located.\n",
    "3. a **Reward Condition** hidden state factor with 2 levels -- this encodes which of the two reward locations (\"TOP\" or \"BOTTOM\") the \"Cheese\" is to be found in. When the **Reward Condition** level is \"TOP\", then the \"Cheese\" reward is the upper of the two locations, and the \"Shock\" punishment is on the lower of the two locations. The locations are switched in the \"BOTTOM\" level of the **Reward Condition** factor.\n",
    "\n",
    "The observations $\\mathbf{o}$ of the generative model are factorized into four different observation modalities:\n",
    "\n",
    "1. a **Location** observation modality with as many levels as there are grid locations, representing the agent's observation of its location in the grid world.\n",
    "2. a **Cue 1** observation modality with 5 levels -- this is an observation, only obtained at the **Cue 1** location, that signals in which of the 4 possible locations **Cue 2** is located. When not at the **Cue 1** location, the agent sees `Null` or a meaningless observation.\n",
    "3. a **Cue 2** observation modality with 3 levels -- this is an observation, only obtained at the **Cue 2** location, that signals in which of the two reward locations (\"TOP\" or \"BOTTOM\") the \"Cheese\" is located. When not at the **Cue 2** location, the agent sees `Null` or a meaningless observation.\n",
    "4. a **Reward** observation modality with 3 levels -- this is an observation that signals whether the agent is receiving \"Cheese\", \"Shock\" or nothing at all (\"Null\"). The agent only receives \"Cheese\" or \"Shock\" when occupying one of the two reward locations, and `Null` otherwise.\n",
    "\n",
    "\n",
    "As is the usual convention in `pymdp`, let's create a list that contains the dimensionalities of the hidden state factors, named `num_states`, and a list that contains the dimensionalities of the observation modalities, named `num_obs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dimensionalities of the hidden states -- useful for creating generative model later on\n",
    "num_states = [num_grid_points, len(cue2_locations), len(reward_conditions)]\n",
    "\n",
    "# Names of the cue1 observation levels, the cue2 observation levels, and the reward observation levels\n",
    "cue1_names = ['Null'] + cue2_loc_names # signals for the possible Cue 2 locations, that only are seen when agent is visiting Cue 1\n",
    "cue2_names = ['Null', 'reward_on_top', 'reward_on_bottom']\n",
    "reward_names = ['Null', 'Cheese', 'Shock']\n",
    "\n",
    "num_obs = [num_grid_points, len(cue1_names), len(cue2_names), len(reward_names)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The observation model: **A** array\n",
    "Now using `num_states` and `num_obs` we can initialize `A`, the observation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_m_shapes = [ [o_dim] + num_states for o_dim in num_obs] # list of shapes of modality-specific A[m] arrays\n",
    "A = utils.obj_array_zeros(A_m_shapes) # initialize A array to an object array of all-zero subarrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fill out the various modalities of the `A` array, encoding the agents beliefs about how hidden states probabilistically cause observations within each modality.\n",
    "\n",
    "Starting with the `0`-th modality, the **Location** observation modality: `A[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the location observation only depend on the location state (proprioceptive observation modality)\n",
    "A[0] = np.tile(np.expand_dims(np.eye(num_grid_points), (-2, -1)), (1, 1, num_states[1], num_states[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build the `1`-st modality, the **Cue 1** observation modality: `A[1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the cue1 observation depend on the location (being at cue1_location) and the true location of cue2\n",
    "A[1][0,:,:,:] = 1.0 # default makes Null the most likely observation everywhere\n",
    "\n",
    "# Make the Cue 1 signal depend on 1) being at the Cue 1 location and 2) the location of Cue 2\n",
    "for i, cue_loc2_i in enumerate(cue2_locations):\n",
    "    A[1][0,loc_list.index(cue1_location),i,:] = 0.0\n",
    "    A[1][i+1,loc_list.index(cue1_location),i,:] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build the `2`-nd modality, the **Cue 2** observation modality: `A[2]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the cue2 observation depend on the location (being at the correct cue2_location) and the reward condition\n",
    "A[2][0,:,:,:] = 1.0 # default makes Null the most likely observation everywhere\n",
    "\n",
    "for i, cue_loc2_i in enumerate(cue2_locations):\n",
    "\n",
    "    # if the cue2-location is the one you're currently at, then you get a signal about where the reward is\n",
    "    A[2][0,loc_list.index(cue_loc2_i),i,:] = 0.0 \n",
    "    A[2][1,loc_list.index(cue_loc2_i),i,0] = 1.0\n",
    "    A[2][2,loc_list.index(cue_loc2_i),i,1] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we build the 3rd modality, the **Reward** observation modality: `A[3]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the reward observation depend on the location (being at reward location) and the reward condition\n",
    "A[3][0,:,:,:] = 1.0 # default makes Null the most likely observation everywhere\n",
    "\n",
    "rew_top_idx = loc_list.index(reward_locations[0]) # linear index of the location of the \"TOP\" reward location\n",
    "rew_bott_idx = loc_list.index(reward_locations[1]) # linear index of the location of the \"BOTTOM\" reward location\n",
    "\n",
    "# fill out the contingencies when the agent is in the \"TOP\" reward location\n",
    "A[3][0,rew_top_idx,:,:] = 0.0\n",
    "A[3][1,rew_top_idx,:,0] = 1.0\n",
    "A[3][2,rew_top_idx,:,1] = 1.0\n",
    "\n",
    "# fill out the contingencies when the agent is in the \"BOTTOM\" reward location\n",
    "A[3][0,rew_bott_idx,:,:] = 0.0\n",
    "A[3][1,rew_bott_idx,:,1] = 1.0\n",
    "A[3][2,rew_bott_idx,:,0] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The transition model: **B** array\n",
    "To create the `B` array or transition model, we have to further specify `num_controls`, which like `num_states` / `num_obs` is a list, but this time of the dimensionalities of each *control factor*, which are the hidden state factors that are controllable by the agent. Uncontrollable hidden state factors can be encoded as control factors of dimension 1. Once `num_controls` is defined, we can then use it and `num_states` to specify the dimensionality of the `B` arrays. Recall that in `pymdp` hidden state factors are conditionally independent of eachother, meaning that each sub-array `B[f]` describes the dynamics of only a single hidden state factor, and its probabilistic dependence on both its own state (at the previous time) and the state of its corresponding control factor.\n",
    "\n",
    "In the current grid world task, we will have the agent have the ability to make movements in the 4 cardinal directions (UP, DOWN, LEFT, RIGHT) as well as the option to stay in the same place (STAY). This means we will associate a single 5-dimensional control state factor with the first hidden state factor. \n",
    "\n",
    "*Note*: Make sure the indices of the `num_controls` variables \"lines up\" with those of `num_states`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize `num_controls`\n",
    "num_controls = [5, 1, 1]\n",
    "\n",
    "# initialize the shapes of each sub-array `B[f]`\n",
    "B_f_shapes = [ [ns, ns, num_controls[f]] for f, ns in enumerate(num_states)]\n",
    "\n",
    "# create the `B` array and fill it out\n",
    "B = utils.obj_array_zeros(B_f_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out `B[0]` according to the expected consequences of each of the 5 actions. Note that we also create a list that stores the names of each action, for interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\", \"STAY\"]\n",
    "\n",
    "# fill out `B[0]` using the \n",
    "for action_id, action_label in enumerate(actions):\n",
    "\n",
    "  for curr_state, grid_location in enumerate(loc_list):\n",
    "\n",
    "    y, x = grid_location\n",
    "\n",
    "    if action_label == \"UP\":\n",
    "      next_y = y - 1 if y > 0 else y \n",
    "      next_x = x\n",
    "    elif action_label == \"DOWN\":\n",
    "      next_y = y + 1 if y < (grid_dims[0]-1) else y \n",
    "      next_x = x\n",
    "    elif action_label == \"LEFT\":\n",
    "      next_x = x - 1 if x > 0 else x \n",
    "      next_y = y\n",
    "    elif action_label == \"RIGHT\":\n",
    "      next_x = x + 1 if x < (grid_dims[1]-1) else x \n",
    "      next_y = y\n",
    "    elif action_label == \"STAY\":\n",
    "      next_x = x\n",
    "      next_y = y\n",
    "\n",
    "    new_location = (next_y, next_x)\n",
    "    next_state = loc_list.index(new_location)\n",
    "    B[0][next_state, curr_state, action_id] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out `B[1]` and `B[2]` as identity matrices, encoding the fact that those hidden states are uncontrollable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "B[1][:,:,0] = np.eye(num_states[1])\n",
    "B[2][:,:,0] = np.eye(num_states[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior preferences: the **C** vectors\n",
    "\n",
    "Now we specify the agent's prior over observations, also known as the \"prior preferences\" or \"goal vector.\" This is not technically a part of the same generative model used for inference of hidden states, but part of a special predictive generative model using for policy inference. \n",
    "\n",
    "Since the prior preferences are defined in `pymdp` as priors over observations, not states, so `C` will be an object array whose sub-arrays correspond to the priors over specific observation modalities, e.g `C[3]` encodes the prior preferences for different levels of the **Reward** observation modality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = utils.obj_array_zeros(num_obs)\n",
    "\n",
    "C[3][1] = 2.0 # make the agent want to encounter the \"Cheese\" observation level\n",
    "C[3][2] = -4.0 # make the agent not want to encounter the \"Shock\" observation level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior over (initial) hidden states: the **D** vectors\n",
    "\n",
    "Now we specify the agent's prior over initial hidden states, the `D` array. Since it's defined over the multi-factor hidden states in this case, `D` will be an object array whose sub-arrays correspond to the priors over specific hidden state factors, e.g `D[0]` encodes the prior beliefs over the initial location of the agent in the grid world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = utils.obj_array_uniform(num_states)\n",
    "D[0] = utils.onehot(loc_list.index((0,0)), num_grid_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative process\n",
    "\n",
    "Now we need to write down the \"rules\" of the game, i.e. the environment that the agent will actually be interacting with. The most concise way to do this in `pymdp` is by adopting a similar format to what's used in frameworks like OpenAIGym -- namely, we create an `env` class that takes actions as inputs to a `self.step()` method, and returns observations for the agent as outputs. In Active inference we refer to this agent-independent, physical \"reality\" in which the agent operates as the *generative process*, to be distinguished from the agent's representation of that reality the *generative model* (the `A`, `B`, `C` and `D` that we just wrote down above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a custom `env` \n",
    "\n",
    "Now we'll define an environment class called `GridWorldEnv`. The constructor for this class allows you to establish various parameters of the generative process, like where the agent starts in the grid-world at the beginning of the trial (`starting_loc`), the location of **Cue 1** (`cue1_loc`), the location of **Cue 2** (`cue2_loc`), and the reward condition (`reward_condition`).\n",
    "\n",
    "*Note*: Remember the distinction between the generative model and the generative process: one can build the environment class to be as arbitrarily different from the agent's generative model as desired. For example, for the `GridWorldEnv` example, you could construct the agent's `A` array such that the agent *believes* **Cue 1** is in Location `(1,0)`, but in fact the cue is located somewhere else like `(3,0)` (as would be set by the `cue1_loc` argument to the `GridWorldEnv` constructor). Similarly, one could write the internal `step` method of the `GridWorldEnv` class so that the way the `reward_condition` is signalled is opposite from what the agent expects -- so when the agent sees a particular signal at the **Cue 2** location, they *assume* (via the `A` array) it means that the \"Cheese\" is located on the `\"TOP\"` location, but in fact the rule is switched so that \"Shock\" is at the `\"TOP\"` location in reality, and \"Cheese\" is actually at the `\"BOTTOM\"` location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldEnv():\n",
    "    \n",
    "    def __init__(self,starting_loc = (0,0), cue1_loc = (2, 0), cue2 = 'L1', reward_condition = 'TOP'):\n",
    "\n",
    "        self.init_loc = starting_loc\n",
    "        self.current_location = self.init_loc\n",
    "\n",
    "        self.cue1_loc = cue1_loc\n",
    "        self.cue2_name = cue2\n",
    "        self.cue2_loc_names = ['L1', 'L2', 'L3', 'L4']\n",
    "        self.cue2_loc = cue2_locations[self.cue2_loc_names.index(self.cue2_name)]\n",
    "\n",
    "        self.reward_condition = reward_condition\n",
    "        print(f'Starting location is {self.init_loc}, Reward condition is {self.reward_condition}, cue is located in {self.cue2_name}')\n",
    "    \n",
    "    def step(self,action_label):\n",
    "\n",
    "        (Y, X) = self.current_location\n",
    "\n",
    "        if action_label == \"UP\": \n",
    "          \n",
    "          Y_new = Y - 1 if Y > 0 else Y\n",
    "          X_new = X\n",
    "\n",
    "        elif action_label == \"DOWN\": \n",
    "\n",
    "          Y_new = Y + 1 if Y < (grid_dims[0]-1) else Y\n",
    "          X_new = X\n",
    "\n",
    "        elif action_label == \"LEFT\": \n",
    "          Y_new = Y\n",
    "          X_new = X - 1 if X > 0 else X\n",
    "\n",
    "        elif action_label == \"RIGHT\": \n",
    "          Y_new = Y\n",
    "          X_new = X +1 if X < (grid_dims[1]-1) else X\n",
    "\n",
    "        elif action_label == \"STAY\":\n",
    "          Y_new, X_new = Y, X \n",
    "        \n",
    "        self.current_location = (Y_new, X_new) # store the new grid location\n",
    "\n",
    "        loc_obs = self.current_location # agent always directly observes the grid location they're in \n",
    "\n",
    "        if self.current_location == self.cue1_loc:\n",
    "          cue1_obs = self.cue2_name\n",
    "        else:\n",
    "          cue1_obs = 'Null'\n",
    "\n",
    "        if self.current_location == self.cue2_loc:\n",
    "          cue2_obs = cue2_names[reward_conditions.index(self.reward_condition)+1]\n",
    "        else:\n",
    "          cue2_obs = 'Null'\n",
    "        \n",
    "        # @NOTE: here we use the same variable `reward_locations` to create both the agent's generative model (the `A` matrix) as well as the generative process. \n",
    "        # This is just for simplicity, but it's not necessary -  you could have the agent believe that the Cheese/Shock are actually stored in arbitrary, incorrect locations.\n",
    "\n",
    "        if self.current_location == reward_locations[0]:\n",
    "          if self.reward_condition == 'TOP':\n",
    "            reward_obs = 'Cheese'\n",
    "          else:\n",
    "            reward_obs = 'Shock'\n",
    "        elif self.current_location == reward_locations[1]:\n",
    "          if self.reward_condition == 'BOTTOM':\n",
    "            reward_obs = 'Cheese'\n",
    "          else:\n",
    "            reward_obs = 'Shock'\n",
    "        else:\n",
    "          reward_obs = 'Null'\n",
    "\n",
    "        return loc_obs, cue1_obs, cue2_obs, reward_obs\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_location = self.init_loc\n",
    "        print(f'Re-initialized location to {self.init_loc}')\n",
    "        loc_obs = self.current_location\n",
    "        cue1_obs = 'Null'\n",
    "        cue2_obs = 'Null'\n",
    "        reward_obs = 'Null'\n",
    "\n",
    "        return loc_obs, cue1_obs, cue2_obs, reward_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Inference\n",
    "\n",
    "Now that we have a generative model and generative process set up, we can quickly run active inference in `pymdp`. In order to do this, all we need to do is to create an `Agent` using the `Agent()` constructor and create a generative process / environment using our custom `GridWorldEnv` class. Then we just exchange observations and actions between the two in a loop over time, where the agent updates its beliefs and actions using the `Agent` methods like `infer_states()` and `infer_policies()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize an `Agent` and an instance of `GridWorldEnv`\n",
    "We can quickly construct an instance of `Agent` using our generative model arrays as inputs: `A`, `B`, `C`, and `D`. Since we are dealing with a spatially-extended navigation example, we will also use a `policy_len` parameter that lets the agent plan its movements forward in time. This sort of temporally deep planning is needed because of A) the local nature of the agent's action repetoire (only being able to move UP, LEFT, RIGHT, and DOWN), and B) the physical distance between the cues and reward locations in the grid world.\n",
    "\n",
    "We can also initialize the `GridWorldEnv` class using a desired starting location, a Cue 1 location, Cue 2 location, and reward condition. We can get the first (multi-modality) observation of the simulation by using `env.reset()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting location is (0, 0), Reward condition is BOTTOM, cue is located in L4\n",
      "Re-initialized location to (0, 0)\n"
     ]
    }
   ],
   "source": [
    "my_agent = Agent(A = A, B = B, C = C, D = D, policy_len = 4)\n",
    "\n",
    "my_env = GridWorldEnv(starting_loc = (0,0), cue1_loc = (2, 0), cue2 = 'L4', reward_condition = 'BOTTOM')\n",
    "\n",
    "loc_obs, cue1_obs, cue2_obs, reward_obs = my_env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an active inference loop over time\n",
    "...saving the history of the rat's locations as you do so. Include some print statements if you want to see the output of the agent's choices as they unfold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action at time 0: DOWN\n",
      "Grid location at time 0: (1, 0)\n",
      "Reward at time 0: Null\n",
      "Action at time 1: DOWN\n",
      "Grid location at time 1: (2, 0)\n",
      "Reward at time 1: Null\n",
      "Action at time 2: DOWN\n",
      "Grid location at time 2: (3, 0)\n",
      "Reward at time 2: Null\n",
      "Action at time 3: RIGHT\n",
      "Grid location at time 3: (3, 1)\n",
      "Reward at time 3: Null\n",
      "Action at time 4: DOWN\n",
      "Grid location at time 4: (4, 1)\n",
      "Reward at time 4: Null\n",
      "Action at time 5: RIGHT\n",
      "Grid location at time 5: (4, 2)\n",
      "Reward at time 5: Null\n",
      "Action at time 6: RIGHT\n",
      "Grid location at time 6: (4, 3)\n",
      "Reward at time 6: Null\n",
      "Action at time 7: RIGHT\n",
      "Grid location at time 7: (4, 4)\n",
      "Reward at time 7: Null\n",
      "Action at time 8: RIGHT\n",
      "Grid location at time 8: (4, 5)\n",
      "Reward at time 8: Null\n",
      "Action at time 9: UP\n",
      "Grid location at time 9: (3, 5)\n",
      "Reward at time 9: Cheese\n"
     ]
    }
   ],
   "source": [
    "history_of_locs = [loc_obs]\n",
    "obs = [loc_list.index(loc_obs), cue1_names.index(cue1_obs), cue2_names.index(cue2_obs), reward_names.index(reward_obs)]\n",
    "\n",
    "T = 10 # number of total timesteps\n",
    "\n",
    "for t in range(T):\n",
    "\n",
    "    qs = my_agent.infer_states(obs)\n",
    "    \n",
    "    my_agent.infer_policies()\n",
    "    chosen_action_id = my_agent.sample_action()\n",
    "\n",
    "    movement_id = int(chosen_action_id[0])\n",
    "\n",
    "    choice_action = actions[movement_id]\n",
    "\n",
    "    print(f'Action at time {t}: {choice_action}')\n",
    "\n",
    "    loc_obs, cue1_obs, cue2_obs, reward_obs = my_env.step(choice_action)\n",
    "\n",
    "    obs = [loc_list.index(loc_obs), cue1_names.index(cue1_obs), cue2_names.index(cue2_obs), reward_names.index(reward_obs)]\n",
    "\n",
    "    history_of_locs.append(loc_obs)\n",
    "\n",
    "    print(f'Grid location at time {t}: {loc_obs}')\n",
    "\n",
    "    print(f'Reward at time {t}: {reward_obs}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Now let's do a quick visualization of the rat's movements over a single trial. We'll indicate the grid location and time of its movements using a hot colormap (so hotter colors means later in the trial), and indicate the Cue 1 and Cue 2 locations with purple outlined boxes. Each of the possible Cue 2 locations will be highlighted in a light blue.\n",
    "\n",
    "Try changing the initial settings of the generative process (the locations of Cue1, Cue 2, the reward condition, etc.) to see how and the extent to which the active inference agent can adapt its behavior to the changing environmental contingencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Cue 1 located at (4, 2), Cue 2 located at (4, 2), Cheese on BOTTOM')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkwAAAF3CAYAAABXMRQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABFvElEQVR4nO3dd3gc1dn38e+9u6ruHWMbbLCxAVNtWjBggyGmkzz0FhICvAnFKU8KkOIEQtqTQguBAAFCTO+hJBgwYErAxlQ3DNi49yZLWml3z/vHjMyySJqVNNIW/T7XpUvSzOyZe2bPztxzzplZc84hIiIiIk2L5DoAERERkXynhElEREQkgBImERERkQBKmEREREQCKGESERERCaCESURERCSAEiYRERGRAHmRMJnZQWZ2v5ktN7M6M1tnZs+a2dfMLNrBsXzPzJ4wsxVm5sxsSgteO93MprdfdFnFMMXMDm+Hclu0LwLKOsnMvtfC14wxs2ozG9TE/J38+c7MhrcyrpPN7CEzW2xmNWY238x+bWbdGol/lZl1bc160sopMbNvm9krZrbRzOJm9omZ3W5m+7al7FbEktW2N/Ha8f5+H9/+kTYbwxQzC/WY5pcZysPqzKynX16L3lsze9zMbmhm/l/9/X93K+Ma6L/XM/16uMbMnjOzQzOWMzObbWY/bM16Msrazcz+7te3uJltMrOXzewyMyv3l2moVxPbur7Oxj8XubSfGjObZ2Y/NbOyRpbf3sxu9I8/cTNbbWYPm9n+acsMzSizqZ/MdTf1c15L1p+27JS0berRyPyvpa2jVeeCpuQ8YTKz7wCvAL2BHwETgW8AC4CbgOM6OKQLgP7Aox283rD8HAg9YQrZSUCLEibg98DtzrllTcz/C7CpLUEB/wskgSuASXj171vAsxkn4seAFcAPWrsiM+sCPAf8AXgDOAs4CrgaGObP60jZbnu+Go9X9/M51p54MWadMPlJy1HAr5uYfzBwNrC5DXGNAU7Dq9enAOcBtcB0M9t2/HXeU45/CVxuZr1buzIzOwWYDYwGrsLbvjOAV4FfABe1tmz5nHeBg/yfY4F78erf/6UvZGZ7AW8DRwO/xXs/LsWrr6+a2Tn+oivSymv4AbgjY9rPMv6/2l/ulIzpT7Zw/ZnqgZMbmf41YEsTr2kb51zOfoBDgRRwXRPzdwb27OCYIv7vGOCAKS147XRgeo73qQOubqdys94XAWXdASxtwfJj/PXv3sT8M4FVwHf85Ya3Mq5+jUw71y/z8Izp3wbWAeWtXNetQBw4qIn5X+ngepP1tjey3Hh/ufEdGXNGDFP8GGLtUW5IZQ31Y/xmC17zBPBAE/NKgPeBy4FFwN2tjKtn5n7zj3/zgZcypkfxTpw/bOW6RgA1wCONvVdAP+DgjHo1MVf1qlB//HPRjEam3w2syqhDH/o/fTKWjQAP4SXPI5tYT+D5Bi8Bb/S43Jr1p33W7yDjfAsMwcsp/t6Wc0FTP7m+GvsRsB5otInXOfeRc+5daLpp3MzuMLNFGdMqzey3fvNenf/7ymyulJ1zqVZtSRPMbKSZPeI3ddeY2etmNqmR5fbyl1tnn3WJXJ42/ygze8q8rsJqM3vfzL5vaV2WafvnyrQmySlp8w/zm9q3mNlWM/u3mY3OiCNqZlenrWe6me2e5bb2M7ObzWyB/9olZjbV0rrRzOwOvCuAQWkxLgoo+pvAu865DxpZZy/gj3gtJBuzibMpzrk1jUx+0/+d2RV4P96J5qstXY+ZDcTbB39zzr3WRCyPpC2/yN9vmeV8oZvUr0ePm9kGvx69YmaHBMXUwm0PZJ7v+vW4zq9PN5hZ94zlYmb2IzObY2a15nUHPWNmo/z55Wb2J7++V5nZSvO6zEellTEF78oZoL6hXqXNz+p4YGb7mNctVGtmy8zsp4Blub2nm9nzfvxV5nVdfS1t/lDgE//fv1kj3RKNlLk93lX31CYW+QFeAvN/TczPinNuo3MukTEtgXfVPyhjehJ4AO8z2RrfwUvGvp25Tr/8Nc65VzImV/p1Z63/c7eZ9UxfwK9Hl5vX7RQ3b3jHH8zv3ktbLrAumFlXM7vezD61z7qHpmXUuazW1xgz6+5vz3L/tfP9z4qlLdPQHXlC0La30Ga8JKXBV4HhwBXOuXXpC/rnwkvx6th32rDO5rRl/XcBh5rZjmnTzgEWAy+1R7Cx9ig0G+ad6CcAjzrnakMsNwb8G9gNr7n3PeBA4Kd43X7fD2tdWcSyPTADr3nwErwuo4uBJ83sOOfc0/5y++NdESwEvgssxbsS2zOtuJ3wummux8u4x+Jl2v2AH/vLHAS8hpd53+xPW+qv41i8Jvcn8ZrwwUtYXzazPZ1zS/xpU/C6Zf4I/Mdfz+NZbnJvP7bLgTXA9nj7+xUzG+W/z1f5Me8HnOC/Lh5Q7iQ/7sb8DpjnnPtHcyefNjjM/z03faJzbq2ZzfVja+qE1pQJeJ+9bPdrVswbG/MyXnfHBUA18P+AaWb2JefcrBYW2ei2Z+lXePXgRrxWkobP415mdljahcm9eF20fwamAeV4Lc8DgXlAGdANr1l/BV4d+zbwmpnt6pxbiddaNxg4HxiH17UIZH88MLO+wPPASrxkNo6XkOyQ5fbuBDwI/AbvCvdQ4FYzq3DO/dWP/avAw3jdaw3v/UfNlHkk3sni5cwZ5o3N+AlwrHOuPu1cGwozK8U7nrzbyOyXgEvNbCfn3MctLPpI4E3n3IoWvOZa4F94Lckj8T7zSbz3qcHdwPF4XTqvArvivd9Dgf+BFp0b/oR3bLoCv+UDOBjvAinr9TXGT8yexOuW/Zkfw7F4x9t+/jpbuu1N8rcZoBKvTp7F549XR/jlNXp8dc4tN7NZtN8wj7as/2W8ltWzgGv8aefgvTft8yW5OWwyHOBv1K+zXH4KjTSN4yUHi9L+P8cv99CM5a4E6oD+Wa6vzV1yeFd+CdKaBfEOgPOBt9KmvQQsASqzXI/58V0JbMDvRnTNNJHiJWPPZUzrDqwF/uz/3wuoAv6asdyPWrov0rZ1iP/ar6RNv4Msu+TS6skFjcw7BO/Etpv//3mE2AyLd3W9Gni2ifn/ABa0otyG/dloM3cjyy8C7mhk+ufeE7yEei5QmvEezMW7MAlt2zOWHU9alxzeySeeGTNeou6AE/z/D/f/v6yFdaoS7yLku2nTp9BIlxxZHg/wErw6YEjaMl38z4dr4b6L+J/PvwHvpE0fSgu65PDGkS1rYt6zpHXB0YYuuSbKvwYv8TukkXk7+9txZivKrQHuyXLZhnp1Z8b0G/AuzMz//xB/uXMzljvLn753C+vC+8Afm4krq/U18drj/GXOy5je0EXftyXb3sx6pvuvz/x5nLRhBMDTwIqAsu4FqpuY19YuuRavn7TPOt6Yurn+9P396SOaW2dbfnLdJdceJuE1yb3qN5vG/Cz7P3hNkQd2YCyHAq875xY2THBek/Y9wN5+02wl3tXLP51z1U0VZN6dLDeb2WK8D3c93lV3T7xB6k0ysxF4B7l/ZuyTarwWqYa7YfbAO0ncn1HEvdlusJl9y8zeMbMqvGTxU3/WyGzLyLC9//tzXUb+FfDNwJ+cc3NaWXaTzLsD7jG8bfh6E4s1tKLlnJlV4LUIPQCk0t5jw2u5ObS512eUlc22N+dAoBTvSi/dvX6ZDS1XR+Ed1P4WEM+pZvZfM9vov34r0JXs6lS2x4OD8D6rDS2tOOe24rWOBTKzEWZ2j5ktw/ts1uN1W7W23oNXt77QVWpmZ+O10LZLa7mZnYnXan2Vc+4LrVtpMXVU3c9sfXgPr+VxgP//JLxj4oONvMfwWd3Pti68CZxnZleY2Vj74p3a2a6vMQ3jdjNbpe/G+8wclDE9aNub8w5ePdkPr+X1W3hJxQPp3X8F7i5glJnthzfm8nXn3IfttbKcdcnhDZitAXYMWrCF+vtl1jcxv0/I62tOb7zukUwr8U5kvfBOABH8rrPG+M24j+MdoKbgdVXU4HVlXInXjdGchoTqNv8nU0NSM9D/vSpjfub/TcV5KXAdXvPyD/Bbv4DXs4ixKQ2vy+y2+w7e/rsurU+/0v/dzcy6OedadaeEn3w8gdfNcphzrqn3pobWbVfDSXlHvNbGMPTGa335qf/zBWYWcQFj9Fqw7UGxgNcNtY1zLmFm69Lm9wHWO+dqmonneOA+4E68O6jW4p1wniK7fZ/t8WAgXstCpsC67yeYz+JdgPwYr5utDu8E9Y0sYmxKORn13l/XH/G6guJpdT8ClPj/b3XONbW9zfL39x3Abc65nzexWMP7VdGKVSyh5cf89Rn/N+yThve/P16ysbWJ1/dJWy6bunAp3jH6G3gtj+vN7C7gSv+iNtv1NaY3Xp2vy5i+Mm1+uqBtb06Vc25m2v+v+J+/+/GSvqfxzjtHmlllMxfsQ/nsmBW2Nq3fObfQzF7D644/mSaOfWHJWcLkHzyn4+2sMudc0DiWWvBaFjIqW2blXIc3uPLUJspZ1IpwW2s9sF0j07fDu7LegJcwpWh+YO3OeGOJznHObbtq9w9u2WgYTHc5XmtDpob92XCCGwCkD7DO5moG4HS8br9tV75mNizL1zalIfZeGdN3w9uPjT1m4C28q6u9W7oyMyvBG4syFjjSOfdeM4v3TouvJabj9dsfz2dXpc2pxTtAp8eZWe834tWjG/Guur4gi2SpJdvenIaD/Hak1SP/KrxP2vy1QG9/nE9TSdPpwELn3HkZcWZ7W3u2x4MVNF7Ps6n7B+GdiA9xzs1Ii7Otx9d1eI+YSNcXb6zLNXw2bqPBELzt/AqteCyKmR2B10L5CM3f2t+w79e2dB14x59vmtl2zht/FoZ1eJ+Rpm5uWJ62XGBdcM5V4R0rL/cHFJ+MNzatDq87Pdv1NWY9Xp3PPI9tlza/PTV8HvfES5iew2sJPRbvvf8cfxzuGLwuw/YQxvrvwjvuJWhBb0hr5LpL7jd4B9DfNTbTzIaZWcPA58X+79Fp83sCX8p42TN4B44q59zMRn5a8yFvrReBA827QwbYNtj9NGC2c26zn1XPAM72r+4b09Bysu3KyD9pnNXIsnV88cpvPt7BYPcm9knDwM538a6aMg8opwdsZ3qcmVdvjXXpxBuJsSmL8A5OO2VM/w3e4On0n9/6886mFXfx+C15/8QbW3OSc+71gJcMoxUtRM655XhX8ReaWWYTfEMsJ6X9u5i0eu87NqPMrXiDIPfCGx/3hfe5uZhase3NeR2vHmbWm9PwLtKm+///B6+ltbn3qhLvQJjuHLzWtHQNF1yZ9Srb48FreJ/VIQ0vNO9ZWdlclDT2+ewFnJhljE2ZBwzJSLxW8sV6PwGvJWya//cMWsivh4/hncDODkiuG5K41rSO/gnvYuEvjXR1YWZ9zXu2VEs8g9fi0qOJ93h52nItOjc45xY75/6A1xU2uoXra8yLeOfdUzKmn4X3mWn0rtkQNZxPG7pVH8ZrEb3GMp6t5R8TrsO7ELu2neIJY/334fXA/MY5t6Gd4vSEOSCqNT94XSspvCbts/Cy9hP8HbQVONFfrifeVfQsvIFz/wP8F+9ksiitvBK8SrkM7+GIR+DdmnsJ3gG62YHVeFfXJ+MlDQ6v+fJk/yfotdP5/KDvhjEIH+Ld5XAcXldCEpiUttx+eM35b+OdDCbgNTFe788vxUscFvpxnMhnd9U5YGhaWbPxDrRH+tuyvT/9GLwD+n3+vjvM38Y/A99Le/1V/vvxe7+MK/AqdOCgb7y7f1L+aybiXQEvyHwtMNmf9i1/2/fIYr8+nkVdOo9GBvqlTR8f8Pqb/OWuxhvPkP4zOGNZw7savLqRWBdlEWtXvMH+1XhdLMfgjW84D++zsCFt2a/7cf0Jrz5/Dy+5zdyv++IN2n8WL1k5zH+vf4V3MAll2xt57fjM/eu/986vX0f57/kWvKQu/SaFB/16+Tu8boLj/bo33p9/Uca2/wivGX8DaYPK8T4TDq/L+gBgbEuOB3gtNxvwBsifhtfd/QpeV4AL2P5+eHfAzsRLZE/135+F6a/FO1Gu9cs9DO/z2SeL/bpvFvVpEY0M+vanTw947Si8urzIX+fn3v9Glp+Md3KvbCTW87KI9RS85PFNvOPcof57cg1e683kjDInZrz+PL543Jvqv38/Bb6Md+y6AK+1bJcW1oXX8FqYjuOzB6ImG+LKdn1NbHsE7zOwBe/cdyRe3XbANY3sz8Btb2I90/Fa2Rvex0P97VyF9/npmbbsPn69/AjvrtpD/ffoebyLlSbfU9o46Ls16yeLZ64FrbO1P6EV1KYgvFaiB/CaxevxPrz/wWspSD+4jsP7kFXjnYjPJuMuOX+5cj4b6xP3y3vTn9bsg+388lwTP9lU0ukZ00biNY9vwmspeZ20ZCmj0jyBlxTW+LH/KG3+3nhXjtV+hf8l3pV55oHjYLykspYvnlAPwrtFdYM/fxFeE+ZBactE8U6aK/04puN1f2WTMFXgnXjX4B0Q/oV3NZoZRxe8ge8b/HmLAsr9Fl4i0KU1H0y8Rzk4YNeA1y9q5r2fkrHswf700RnT38QbeJhNvS/xY3sV7/kodXhdBreS9sBWvIPsz/AuDqrxbo3euYm4dvXf09V4dX8p3tXXMWFteyOvHc8XEybDe0TGfH+7VuA1m3fPeG3D3Z4L/OXW4F1UjEzb9qvxujmq8U54+5Bx56Bfb2/0tzvF5xOVrI4HeAnny3ifjWV4J8NfpJfVzD44HO9ipQbvwH8ZjdzZi5eIzcE7zjWbYPjbtAz4eRbrX0TjCdMa4N4sPzeN/jSy/LPAgxnTjvWX/8KxrYl17o53rP3Uf983+fv+20BZRr3KJmGK4CVy7/jv3yb/79/htQRlXRfwWqpn+2VsxWtduiwjhqzW18S2d8e7222Fv+0L8D4rlrZM1tvexDqmZ7yPdX69vJlGLoDwHsvxF78eNXwOH6WJB+umva7NCVNL108OE6aG2zJF8pZ5DztcivewuxZ/X5aZTcW7ojomxJhuwkuWDkmb1gUv4T3LOZd5p6FIi5n3UM6z8FotWnSwNrNd8BLWA5xzb4QUz/Z4rW5HOeeeS5t+DV7PwB4tjVOkUGQ1hsnMJpn3NNKFZvbj4FeIhMc5txnvqu+Hrbwd9lA++z6jNjOz7fAeHHdlxqwv4XXDPBjWuqTT+xPecIQmH4bYjMPwnqMVSrLk+wHwYnqylLaua5QsSTELbGHyB+YtwOtrXYrXfHmGa4dn34g0xR8Q/wPgVtf8oMqOiOVAYB/n3E25jEM6B/O+Sqm3c66lT5QPOw7D+xqrx51zrXn6u0hByyZhOghvDMOX/f8vB3DONfrt2SIiIiLFJpsuuUF8/qFRS2nFl3GKiIiIFKrQHlxpZhcCF/r/jgmrXBEREZF2ttY516+5BbJJmJbhPeyrwWAaebqyc+4W4BYAM9PAPxERESkUi4MWyCZhehMY4X/FxTK8B+Kdmc3aJ57Z7MOFJcO0qWO3/a1913Lp+2/yda36GrlO7drLum37W/WvZfTZbRvtv7bR/mub9P3XnMCEyXnf+XYJ3sPyosDtzrkPAl4mIiIiUjSyGsPknHsK7+m7IiIiIp1Orr98V0RERCTvKWESERERCaCESURERCSAEiYRERGRAEqYRERERAIoYRIREREJoIRJREREJIASJhEREZEASphEREREAihhEhEREQmghElEREQkgBImERERkQBKmEREREQCKGESERERCaCESURERCSAEiYRERGRALFcB9De4ltXsu7TaWxaNZOaTR+TStYRiZXTpddIegwYS58djqSkvGeuwxQREZE8VrQJU82WJXzyxq/ZvOZtAFyq7nPz41VL2bj8FRa99Sd6Dx7P0DHfp7SiTw4iFRERkXxXlAnTivn38unb15NK1YNLNblcKlkLwPolL7Bx+SsMP+gX9B4yvoOiFBERkUJRdGOYFr99PZ++fQOpZLzZZCmdc/UkE1v58NUrWbXw0fYNUERERApOUSVMqz9+gpXz79vWctRSqWScRbN+z+bVb4UcmYiIiBSyokmY4tWr+WTm71qdLDVIJeMsmHE5yURNSJGJiIhIoSuahGnJuzeRStYFL5iFRH0VKxfcH0pZ0vm8/tQ13Hz5jk3O/+8zv+XhG47nph9sz7WXdWPzusUdGJ2IiLRGUSRMifoq1i7+D7hkKOW5ZJwV86bishwDJdIS779yO6lUgsEjDsl1KCIikqWiuEtu88qZRCxGknhoZSYT1dRs+pjKnsNDK1ME4Bu/mItFInz8/tN8/P5TuQ5HRESyUBQtTFvWvd8uY46q1s8LvUwRixTFx05EpFMpiiN39caFQLjdZ6lEDbWbNbZEREREiiRhcqlEu5SbStW3S7kiIiJSWIoiYSop7xV+oRbVd8yJiIgIUCQJU7e+e2LRslDLjMYq6NJrVKhlioiISGEqjoSp354YFmqZqWQdXXrvGmqZIiIiUpiKImGq7LkLpZX9QizR6LHd/pSU9QixTBERESlURfEcJjNj8B4X8fF/r27zV6MARKJlDB59fgiRSWeVStTz4exHvzB90PCDWb9yPjVVa1m9ZDYAi+Y8S0XXvvTebhR9BqobWEQkHxVFwgTQd8cvs+rDh9iy9t02PfHbIqX0HTqJbn33CDE66Wzq4lt46u/nfGH6/1z6FK8/fQ3LFs7YNu2FB74LwAGTLqfPwCs6LEYREcle0SRMZsYuB1/DO0+fSSK+EXCtKCRGWZeBDN33e2GHJ53IgcdcwYHHNJ34nDzi6Q6MRkREwlAUY5galFb2Y4+j/k5JeW8sUtqi10ai5VR0G8LoI28jWlLZThGKiIhIISqqhAmgvNtg9j7uIfoMOZxItBwsYBMtRiRaxna7nMKeR/9Tz14SERGRLyiaLrl0sdKujDj4aqrWz2P53LtZv+R5LBKlIhnHAfFYBS6VBDP6DTuOgSPPoKL7DrkOW0RERPJUUSZMDbr2HsUuB1+NSyWp2fIpp7z8Q+pw3LfXJVT2Gk5Zl0GYhfv8JhERESk+RZ0wNbBIlMoew5jgf4XKs0PG5zYgERERKShFN4ZJREREJGxKmEREREQCKGESERERCaCESURERCSAEiYRERGRAEqYRERERAIoYRIREREJoIRJREREJIASJhEREZEASphEREREAihhEhEREQmghElEREQkgBImERERkQBKmEREREQCKGESERERCaCESURERCRAYMJkZreb2Woze78jAhIRERHJN9m0MN0BTGrnOERERETyVixoAefcS2Y2tANiERGRTmby/IuYPGbMZxPmX5S7YApU5v67duTNuQumiJlzLnghL2H6l3NudFaFmgUXmgMv+L8n5DQKERFp8ET6yV5CcfysWbkOoRDNcs6NbW6BwBambJnZhcCFYZUnIiIiki9CS5icc7cAt0D+tjCJiIiItEZoCVNjJp45sz2Lb7Fe07wGsIkTb8lxJI2bNvWz1sB823eFQPuvbdL33+TrtuQwksJz7WXdtv2tutdCGrMUOtXBlkk/9jUnm8cK3AO8Bow0s6Vmdn4bYxMREREpKNncJXdGRwQiIiIikq/0pG8RERGRAEqYRERERAIoYRIREREJoIRJREREJIASJhEREZEASphEREREAihhEhEREQmghElEREQkgBImERERkQBKmEREREQCKGESERERCaCESURERCSAEiYRERGRAEqYRERERAIoYRIREREJoIRJREREJEAs1wG0O5fC1s0hsu4DHt68mHqXJPbGr3G9R5Hqszuu5wgwy3WUIiIikseKN2FKxonOv5fYvH9CohZckreScQBiCx/CRcsBw1X0Jrnb10nudDxEormNWURERPJSUSZMtvZ9Smf8COKbsGRt48v4061qGfbWH4guuI/6cb/Fdd+hI0MVERGRAlB0Y5giS1+k9Ln/h1WvajJZymSJGmzjQkqfORtb90E7RygiIiKFpqgSJlvzLiWvXJl1ovS51+KwRDWlz30bq1rWDtGJiIhIoSqehClRS+mMH7UqWfqcZA0lr1wBLhVOXCIiIlLwiiZhis69C+o2t7kccyls48dEFj8bQlQiIiJSDIpj0HcqQWz+vZh/F1xbWbKG2Jy/Uzf0y6GUJyLZe/2pa3jn5Zu56NeLvzBvw6oFvP3iX1ny4YtsWb+Eyu4D2Gn00Rx49BWUVfbs+GBFpNMoioQpsno2uGSoZdqWJbB1BXQZGGq5ItJ6n85/geWfvM6e475J3+1Hs2ntJ7z25FWs+OQNTvve81ikaBrNRSTPFEXCZOs+gEQ4rUufFRojsm4OKSVMInljlzEns+chF2L+w2YHjziErj0H8ehNJ7Hso1cZPGJcjiMUkWJVFJdjkXUfYC4RbqGJamzTR+GWKSJtUtGlz7ZkqUG/wXsCsHXzilyEJCKdRFEkTCSqQy/ScFh9+OWKSLhWLnoDgJ79huc4EhEpZsWRMMUqQy/SYbiS8MsVkfDU11Uz4/GfMWj4OAbssE+uwxGRIlYUCVOqz2hcJOThWCWVuJ66YhXJV845pk29mJotazjyzL/kOhwRKXJFkTC5vrtDpDTcQlMJUr13C7dMEQnNK4//lI/efYLjLriHHn2H5TocESlyRZEwpfrtDZGSUMt03YdCl+1CLVNEwvHWCzcw6/nrOOrsWxi088G5DkdEOoGiSJiIxEiMOhMXLQ+lOBerILH710MpS0TCNe/N+3j50Ss49KRfs8u+X811OCLSSRTFc5gAkrueTWzhw1Ddtu+ScxbF9RxBasgRIUUmIi2VStTz4exHvzC9omtfnp36LXYceQTbDd2PFZ+8sW1e156D6NZrUAdGKSKdSdEkTETLqBv3W0qf+39t+wLeWAV1B18DGc96EZGOUxffwlN/P+cL0wcNH0cqWc/iedNYPG/a5+YdMOlyDjzmio4KUUQ6meJJmADXdzT1h/yOkpd/CMlaWpLyOItArJK6I/6qsUsiOXTgMVco8RGRvFMcY5jSpLb/EnVH3orrOijrMU0uWoHrNYq6o/+J6z2qnSMUERGRQlNULUwNXO9R1B37INGFDxKb8w+o3wLObeuqc+A97NKlcF22I7H7N0gNnQRWdPmjiIiIhKAoEyYAoiUkR55BcpfTsQ3ziayfy7h3b6aOFG/u+GVSvUfh+uzuPT5AREREpBnFmzA1MMP1HkWy9yiOX/Q0AK+N+X6OgxIREZFCoj4oERERkQBKmEREREQCKGESERERCaCESURERCSAEiYRERGRAEqYRERERAIoYRIREREJoIRJREREJIASJhEREZEASphEREREAihhEhEREQmghElEREQkgBImERERkQBKmEREREQCKGESERERCaCESURERCRArD0KHVg5nIt2/RPMX9Eexbdaj+o6AMblWVwNxo154rN//BhnjByYo2hERESkQWALk5kNMbMXzGyOmX1gZpM7IjARERGRfJFNC1MC+L5z7i0z6wbMMrNnnXNz2jk2ERERkbwQmDA551YAK/y/t5jZXGAQoISpA0ybOjbXIRQk7be2ufaybrkOoWCp7rXM5DFjch1C0VEdbB8tGvRtZkOBfYD/NjLvQjObaWYzqxObQgpPREREJPeyTpjMrCvwEPAd59zmzPnOuVucc2Odc2MrYz3CjFFEREQkp7K6S87MSvCSpX865x5u35Ak3cQzZ+Y6hIKR3gyt/dZy2n+tp33XBvMvynUERUd1sGWy7cIMTJjMzIDbgLnOuT+2MS4REZFtrh15sxLONtL+6xjZtDAdDJwDvGdmb/vTrnDOPZXtSs65b9dWhBa+AWdWAnDO1PyIB+Afp83NdQgiIiISIJu75GYA1gGxiIiIiOQlfTWKiIiISAAlTCIiIiIBlDCJiIiIBFDCJCIiIhJACZOIiIhIACVMIiIiIgGUMImIiIgEUMIkIiIiEkAJk4iIiEgAJUwiIiIiAZQwiYiIiARQwiQiIiISQAmTiIiISAAlTCIiIiIBlDCJiIiIBIjlOoCOkKqvZ8uCBWxdu5aEc2x98km6jRxJ12HDsGg01+GJiIhInivqhGnD7Nks/NvfWPXCC0RLS7GaGhzAFVfgnMMlkww6/nh2Pv98uo0YketwRUREJE8VZcJUt3Ej7155JatfeolkbS04R6K+/rMFtm7d9ueSRx5h2b/+xQ6nnspuP/wh0fLyHEQsIiIi+azoxjBVffIJLxx1FKteeIFkTQ041/wLkklStbV8ev/9vHjcccTXreuYQEVERKRgFFXCVLN8OTNOOYW6DRtI1dW16LWp2lqqly5lximnkKiqaqcIRUREpBAVTcLknGPW5MkktmwJblVqqoxEgtpVq3jvl78MOToREREpZEWTMC199FE2z5uHSybbVE4qHmfF00+zftaskCITERGRQlcUCZNzjgXXX++NWQpBsraWBTfeGEpZIiIiUviKImHa9MEHxNeuDa9A51j3+uvUbdgQXpkiIiJSsIoiYdowe3abu+IyRcrK2Pjee6GWKSIiIoWpOBKmt94iFY+HWmaypobNc+eGWqaIiIgUpqJImNqj68wlEsTXrw+9XBERESk8RZEwWUlJu5QbLS1tl3JFRESksBRFwtR91CiIhLsp0cpKuuy0U6hlioiISGEqioSp1157EausDL3cnrvvHnqZIiIiUniKImHqe9BBpBKJUMss6dqVrsOHh1qmiIiIFKaiSJhiXbow+MQTsVgslPIi5eXsdP75WMjdfCIiIlKYiiYjGDl5MpGQBmmX9OjBjmeeGUpZIiIiUviKJmEq79+fPa+6imhFRZvKiZSXM/a664i1sRwREREpHkWTMAEMPvFEdvrmN1udNEXKy9nz6qvpPWZMyJGJiIhIISuqhAlg1OTJ7H7llUTLy7FoNKvXWEkJsW7dGHv99Qw56aT2DVBEREQKTtElTAA7nn464595hn6HHkqktJRIeXmjy0UrKoiUlTHouOM44vnnGTBhQgdHKiIiIoUgnNvK8lDl4MEc8Le/Ubt6NSueeYZ1b7xB9QsvkHQOhgyh5x570Gf//Rk4aRIl3bvnOlwRERHJY0WbMDUo79+fYeeey7Bzz2Wgf+fbiqlTcxyViIiIFJKi7JITERERCZMSJhEREZEASphEREREAihhEhEREQmghElEREQkgBImERERkQBKmEREREQCKGESERERCaCESURERCSAEiYRERGRAEqYRERERAIoYRIREREJoIRJREREJIASJhEREZEASphEREREAihhEhEREQkQ64iV/OO0uR2xmkBfm18N5E88IiIiUhgCW5jMrNzM3jCzd8zsAzP7RUcEJiIiIpIvsmlhigOHO+eqzKwEmGFmTzvnXm/n2EREpMhN22UsTEn7n7E5i6VgTfnsz2mMZeKCmTkLpZgFJkzOOQdU+f+W+D+uPYOSz0ybqoNHa2i/tY32X+tp37XQlFwHUHxUB9tHVoO+zSxqZm8Dq4FnnXP/bWSZC81sppnNrE5sCjlMERERkdzJKmFyziWdc3sDg4H9zWx0I8vc4pwb65wbWxnrEXKYIiIiIrnTorvknHMbzewFYBLwfvuEJOkmnqm+6GylN0Nrv7Vc+v6bfN2WHEZSeK69rNu2v1X3WkZjlsKnOtgy2XZhZnOXXD8z6+n/XQEcCcxrS3AiIiIihSSbFqaBwJ1mFsVLsO53zv2ruResqF7IlFnH512We9KSUgBmjByY40gapxYSERGR/JTNXXLvAvt0QCwiIiIieUlfjSIiIiISQAmTiIiISAAlTCIiIiIBlDCJiIiIBFDCJCIiIhJACZOIiIhIACVMIiIiIgGUMImIiIgEUMIkIiIiEkAJk4iIiEgAJUwiIiIiAZQwiYiIiARQwiQiIiISQAmTiIiISAAlTCIiIiIBYrkOoKOYS0GyDlyKHtWr2VTRD8xyHVbBKEnG6RtfQ4QUm0p6UlXSPdchiYi0u66lXRnQZQBmxsqqlVTVVeU6JMmRok6Yyuq3su8nT/OlhQ/Tf/MiLFUPZlz+xFdwGMt7jeCVXU7jnSGHk4yW5jrcvDOgZjknLr2PQ1Y/T9/4auojpTiMklQd1bGuvNNzXx7e4Uw+6LGXkk8RKRqj+49m8gGTOXr40fTr0o94Ig5AWayMNVvX8MzCZ/jzf//M+6vfz3Gk0pGKM2Fyji99+CDHz74WMMqSNZ+bV5r0Kv+wte8xcONHfHXmb7n3gJ/z/pDxOQk331Qmqvj2/P9jwur/ePvL1QMQS9uPPeo3Mm7NC+y37jWWVw7mV6N/zZIuQ3MUsYhI223XdTvuOPEODtnxEEoiJZRESwAoTbugHtR9EOfudS5njD6DGUtm8LVHv8bKqpW5Clk6UNGNYSqr38rF0y7k+NnXUZas/Xyy1IjyRDWVdVs469WfcNYrPyGSSnRQpPlpaNVC7nj1K4xf9SylqbptyVJjIjgqUjUMrVrIX944i6OWP96BkYqIhOfwYYcz/5L5TBg2gcqSym3JUmNKoiVUllYyfuh45l8ynyOGHdGBkUquFFXCVJKo5eJpF7LDug8CE6VMZcla9lg6nfNe/qE33qkT2qHqY/4883x61G+gzMWzfl0UR3kqzqXzf8ekZY+0Y4QiIuE7fNjhPH7643Qv6/651qQgpdFSupd157HTH+PwYYe3Y4SSD4oqYfrKzN/Tf/MiSlJ1rXp9abKWESvf4NB5U0OOLP+VJONc885lVCSrW10pylO1XLzg/xi25cNQYxMRaS/9u/Tn4VMfpktpl1aX0aW0C4+c9gj9u/QPMTLJN0WTMA1bPZt9Fz+zbXxSa5Ulazn63Zvos2VpSJEVhvM+/is96jYSwbWpnNJUHT99/8edtpVORArLbSfcRnmsvM3llEXLuP2E20OISPJV0SRMx7xzY5uTpQbRVIIJc+8MpaxCUJHYyglL76c8VdvmsiI4+sTXMHbdayFEJp3R609dw82X79jovK2bV/HELadx28935Ybv9eVvPxnOk7efw4bVCzs4SikGI3qP4PBhh1MWK2tzWWWxMiYMm8CI3iNCiEzyUVEkTL2qlrPD+jmhlRd1ScZ+8jQlibYnEIXg8JXP4AjvsQCVyWpO/fSu0MoTaZCoq6assicHHfMTTvrWIxz6ld+wYfWHPHzDccSrN+Y6PCkwl+x/CbFIeDeLxyIxLj3g0tDKk/xSFI8V2Hn1W6QsGmqZyUiUQRvmsajf3qGWm48OWvsSFSG0LqXbddN7mEvhrChycskTPfoO46izb/7ctP5D9uauq/dhyYcvMnyvE3MUmRSio4cf3aJB3kFKo6UcPfzo0MqT/FIUZ7Oha9+hLNGyu+KCxJL1DFk/L9Qy89WILeFvZ4oo29d0rnFgkhsVXXoDkEw0/QgMkUwlkRJ27Nl4129b7NBjh1CTMMkfRdHC1Gtr+A8NK0nVcdKcf3DikudDL7spG9L+7jXtwg5bb0/WE2KPHABJi9Irvo5llTuEW7AI4FIpUi7J1k0reO1fV9Gt9w4M2/3LuQ5LCkivil4kUonQk5tEKkGv8l6s2roq1HIl94oiYWo3+raPNnH6uhRpJ88/8F3ef8W7I6lHn2F85duPUVreLcdRSSFxzmHtdJB3bbzbWPJTUSRMa7sNIbXi9TbfEp+uLlrG47udx6u7nBJamUGmTR277e+JE2/psPVOnXEM/eKrQy0z5hKsK+sXapkiDfY78n/Z/cBz2bJ+CW89fy2P/uUkTv3e83TprufgSHbW16wnGgl37Ct4A7/X16wPvVzJvaIYw7S4zx7UxSpCLTNpMZb23jXUMvPVgm7hb6cDVpZvH3q5IgDdew9hux3HMGKfkzjp248Rr9nEuy933EWGFL6kS/LRho9CL/fjDR+T6ORfsVWsiiJhWjhgLNGQK6jhWNZrl1DLzFcz+k+gOhpewpnCeKfXGFCXnHSAsoru9Og7jE3rFuU6FCkwj857lNoQHx9Tm6jlsXmPhVae5JeiSJg2V/Zj4YAxhPVs6UQkxus7n0Syk9zp8FL/iaH25NdGy3lgx3NDLFGkaTVVa9mw+kN69An/jicpbje9eRPOhTeUwznHjW/eGFp5kl+KYgwTwFN7XczOq98K5WnfyUgJ03c9J4SoCkNdtJx7dvw6Zyy6vc3PY0oQYUnlUN7tuW9I0UlnlErU8+HsR78wfdPaj9mycRmDdj6Yym792LRuEbOn30g0VsroL32j4wOVgrZk8xIenPMgJ+92MhUlbWtlr6mv4aG5D7Fk85KQopN8UzQJ07Leo3h5l9M5ZMF9lCZbf9KPR8t5ZMwP2FzZuQYs37fjuRy+6hkGb11ErA1tdYlIKVfv8Wt1x0mb1MW38NTfv3jR8pWLH2fx/Of58K2HqItX0bXnIAYPH8f+k35Mt16DchCpFLpLnr6EScMntTlh2lq/lYufujikqCQfFU3CBPD0Xt9i8Ia5DFvzbquSpni0nFnDjuaNnY5vh+jyWyoS44q9r+PGN86hW/2mViVNtZEyrhn9K1ZWDG6HCKWzOPCYKzjwmCuanL/DyAkdGI0Uu83xzUz65ySmf2063cpa92iKLfEtfPnuL7M5vjnk6CSfFMUYpgapSIxbD7uW9wcdSjzasm+frouWMWOXU3lwvys6bevImvLtuHj/f7CyYhC1kez3X73FqI5WctUev+W1foe1Y4QiIuF7a8VbHHbHYayqWkVNffbfGlFTX8PqrasZf+d43lrxVvsFKHmhqBImgGS0hLvHXcPdB/+KqrKe1MYqm1w2hRGPVbCuyyBuOvwmntznsk6bLDVYU74d3zzwAR7c4UzikTJqmkmc6i1GPFLG7F77cd5BD/NG33EdGKmISHhmr5zN8OuHM/W9qdQmaptNnGrqa6ipr+Ge9+9h5+t2VrLUSRRVl1y6DwYfxpTtD2bX5TM4cOGjDFk/h67xjaSIECHFpop+LOq7J6+O+B8+6q9b4NMlIzHu3PnbPLDjuRy1/AnGr36WYVULqUhUA95dhMsqhzCz94E8MfhUllcOyXHEIiJtV1VXxTef+CZXPn8lF465kBNHnsiu/Xal3ErAQZwEc9bM4fEFj3PzzJv19SedTNEmTOB10X0weDwfDB4PQDRZTyxVR320jFSkqDc9FNWxrjy6wxk8usMZ4Bx/eO4CDMf3J/wNZ0XXOCkiAsCqrau46qWruOqlqwB48Z4KMOOw06tzHJnkUqfKGpLREpLRklyHUZjMcP6XzyhZEpHOJFWb/bgmKV4684mIiIgEUMIkIiIiEkAJk4iIiEgAJUwiIiIiAZQwiYiIiARQwiQiIiISQAmTiIiISAAlTCIiIiIBlDCJiIiIBFDCJCIiIhJACZOIiIhIACVMIiIiIgGUMImIiIgEUMIkIiIiEkAJk4iIiEgAJUwiIiIiAWLZLmhmUWAmsMw5d1z7hSSSvXHzV3z295gnPpuRNl2y87n9d+d0ADZ8bXxOYhERyTctaWGaDMxtr0BERERE8lVWCZOZDQaOBW5t33BERERE8o8554IXMnsQ+DXQDfjfoC45MwsuVArOC/7vCTmN4vOmpHcjSeimzDo+1yFIsZuS6wCCvfB37/eEr+c2jqxNyXUABWmWc25scwsEtjCZ2XHAaufcrIDlLjSzmWY2s4VBioiIiOS1bLrkDgZOMLNFwL3A4WZ2d+ZCzrlbnHNjgzI0ERERkUITeJecc+5y4HIAMxuP1yV3djaFTzxTjU0tMW3qZ7lmPu67XtMuBGDixFtyHEka3Q3XrvKxHuajfP/s5rNp6Bo7bKqDLZP++W1O1o8VEBERCdvEBTPzPuHsVeNfLC7Io4vFNPm+/4pFixIm59x0YHq7RCLSDvQcoeb18p+3JCIizdOTvkVEREQCKGESERERCaCESURERCSAEiYRERGRAEqYRERERAIoYRIREREJoIRJREREJIASJhEREZEASphEREREAihhEhEREQmghElEREQkgBImERERkQBKmEREREQCKGESERERCaCESURERCSAEiYRERGRALFcByD5K0KSsbzGOHue3XmXQRM+BYOpdgwL2JU33MFM5yiq6ZrrUPNSGVvYJ/Ygu0X/w5DIbCpsE44Im90APkkeyLvJE5ibPBJHNNeh5qUBPZczcd8n2WfnN9mx/8eUlcSpT5awbO0Q3vlkDM/NPoZFq4bnOsw85dh9l4847MBZ7DFqIdv1XU8kkqI2XsZHiwcx671dee6VA9i4uVuuA81LJbEU4/bbxIH7bGbU8GoGVF4AwF01c5n7YSWvz+7OjDd7UJ9Qm0NnooRJGuE4gqe4yP5MGXEqrdqbXOL96sdq+rGaffkv3+IPPMVXuN1dQpzy3IWcR0qo5tiSX/Clkr/jMMoa9p+vwjYzIPIhe8ceod6V83j91byZOBOw3AScZwb0XM73vno1uw99GzNHaax+27wKaui+wwfsMmguJx10H0vXDOUPD/+UhctH5TDi/DJmjzlc9vV76dVjM2Wl9UQibtu8yoo4vXtuZs9RC/nGqY/zyqy9uOGO09hcpYsegIg5Tjl2NWectBoDKitS/pxSAAZ2q2Ng/zoO3Hczk89fyj2P9ueBJ/uTcvrsdgZKmORzurCFn9mP2JV3qbDaZpdtmH+Me4RD7Tl+4v7ER3TuE9egyLtcUHYylbaRUqtpdtlyq6Lcqji59HvsF72Hv8fvpoaeHRNonvrymMe4+ITfUxKtJxZNNrlcNJoiGo2z08D5/Omi83nw5bO5c9r/ozMnnbFogu+cP5XDDnyL8rK6ZpctK/OS0IPHvsN+e87hV9efz8z3duuIMPNWvz51XP2/nzCwfx0V5alml21IpM76ymqOGLeRn/zfMFavLe2IMCWH1J4o23RhC9fbeYxmdmCylK7c4vS1NfzJLmAk77djhPltSGQWl5UfRc/IisBkKV2ZVTMs+hrfqZhABRvbL8A89z/j7uaSE35PRWlts8lSukgEykvj/M8h/+S7X7kacIGvKUaxaIJrfngDhx04KzBZSldakqBrlxp+/t2bOXjs2+0XYJ4b0LeOv1y9gB0G1QYmS+kqylMM2b6WG69awIC+2e93KUxKmMTnmGL/ywCWU2r1wYs3osJq+I1dQg82hBxb/uvCGr5VfiJltrVVry+xOnrbp5xffjqd8aQ/dpdXOe/Iv1Jemn2inq6itJYJe/+bk750T8iRFYZvnfMAu474hPKy1n12y8vq+fG3/87QwctDjiz/lcRS/P7Kj+jWJUmsFcMJY1Ho1iXJ76/8iJJY9smWFB4lTALAUTzBSOa0OllqUEqc/7VfhBRV4Tij7GJKyL5VqTElVseQyGwOiP0jpKgKQ2VZFT8+9aetTpYaVJTWcv6X/8LA3ktDiqwwjB65kKMOfb3VyVKD0pIEP7nsViKR7Fr3isXXTl5Jrx71RNtw70U0Cr161HPeKSvDC0zyjhImIUKCi+zPVLSgG6kppVbP3sxkZ+aFEFlhGBR5l12i0ymxtjfJl1k1J5ReSYRE2wMrECcddB/lJW2vewCxaB1fP+ovoZRVKC4+9/42J0sAkYijX+8NjBv7TghRFYbuXROc9OW1lJe1vVW3vMxx4lFr6d6183x2OxslTMJBvEwsxBN0jDpOsbtDKy/fjY9dT5Twxi9ESTA6+mRo5eWziCX56rh7KCsNZ//Foim+tNt0ulVsCqW8fDd0yDIGD1wVWnmVFXFOO+HfoZWX7yaNX4cLsQfcOTjm8HXhFSh5RQmTcKg9+9mjA0IQsxQHMCO08vLd7rGniVp43RjlVsXesUdCKy+fDR3wESWxcAfLJpIl7LPzm6GWma8O3Oc9otFwx83sNGQZlRXhtPjlu8O/tDGU1qUG5WWO8QduDK08yS9KmIRd2+HOtlLq6MOa0MvNN91tBSW0bexNY3aMdI4T/ohBcwl7kHt5aTWjhrwXapn5as9RH1ISC3fMUW1dKcN3XBJqmfnIzDFkYDz0cocMjBOxznfjRmeg5zAJvVkbepnRRIKrZk+memP7PhCvR3XzrROJ63q26/rLB20mcmqCsJ/Z2Su1hEuuOzrcQhsRW7mx2fknLWnfZ8tsN3wZlWXhtmZEI44vR59gl2lzQy23Oen3hfaadmGHrXfUVVHCfvZURaqGyav/wIZpHXfSz8X+i/YpJ5b6GmGfBh3QvVuCjZtLQi1Xck8tTEKkHW5jdxjWGa6y2mkbrbM8f7G9vhUm2gnqHrTP/jOwTvBtPRaJtMsTPJzzng8mxUctTEI1lfQg3EGydbEyfjPmahazc6jlZho3f0Wz8zd8bXy7rn+AzeO7ZROIUhVqudWRntxw2dOhltmYXndOb3b+jJED23X9J/e7m68nbvzc15+E4b+lh/C7ib8MtczmTJs6dtvfEyfe0mHrvSHxG0byaahl1lgFt+5wLq9O3DvUcpuTi/1XWpLisZL3Qm81iEUdW6s7QcbZCSkPFj5ml9DLLKGeJewYern5Zo0bTizEO+QaLEvuEXqZ+Wjh8pHU1ZeFWmZtXTkfLN4r1DLz1fsLdiaVCrc5MhZN8uGiHUItMx/V1UdYtzH8brP1m0qI1+nUWoz0rgpvuoOodeGetD5mOKlO0ICZIsayVLjJTZ0rZ15qYqhl5qsFy3YN/S45gPcX7R16mfnonTkjqakN97MbrytlzbpeoZaZr97+oCuJEMfMJ5Pwzpwu4RUoeUUJk/Asx4U6jqnaVfKgOzu08vLd9PpLqXXhDW43HG/Ud479Vx3vymtzDyUZYivJ8nWDWby6fbuC88Ub7+weagtTPB7j0X+Pp7N8ifGj/+lLIhHettbVG4880y+08iS/KGESNtKbF5lI3IVzR1QtFczg8FDKKgTvJo8n7sK5qqx3ZbyTOJEqOs9B954XvkEiEU7dq4mXc9e0i0IpqxAkk1Hu/9eR1NSGs/9SLsK/njsklLIKwcJFlSxaWk4yhFamZBI+XVbOh4sq216Y5CUlTALAje4HxKloczm1roxfuV+RoPPcUpuklLvid1Dn2r7/6qjkobo/hBBV4fh45S489vop1Na1rWupPhHj3U/25ZU548MJrEDc/+SRrFnXq80tTTW1pdz0j5PZuLl7SJEVhl/fuCP1IbQy1SeMa24s/nGbnZkSJgFgK92Y4n5PrWv9A4VqXDkPubN4l7HBCxeZj1LjeKH+UuKu9VeXda6C22unUkPP8AIrEHf859ssXrUz8frWtZQkklE2VvXmdw/8ks7SndQglYrysz/+P6pry0i18qHftfES3nxnN56efnC4wRWA5avK+PNtg6mNt77e1MaNa28fzPJV4Y4nk/yihEm2eY99+Zn7AzWugoRr2W2xta6cRzmdO/hWO0WX/56u/wkv1l/c4pampIsSd124tfZePkqNa6fo8lt9spQf3HoTC5ePoibesqS9tq6M1Ru349Kb7mBzdc/2CTDPLVs5gO/+8vts2dqFurqW3WxRU1vKf2eP5pobz6ezJZsNnnulNzfcMYjauLUo6UylvGTpxjsHMW1G7/YLUPKCEib5nNkcwPnuAeaxOzWugpRr/gBa7SrY4HrxM/dHbneX0FkPuB7jqfqf8bfaB9iS6hc4EDzljFrXhU9TY/hNzRssSHWecV+Nqanrwvdu/ht3TbuI2roy4gFddHWJEuL1ZTz95klc8Of7WLe5fwdFmp8WLRnE178/hddn70FtvIREovnDe01tKVtryvjTbWdy9fXfJJns3M8O+vdLfZg8ZQTLVpVRXRN8aqyuibB8VSmTp4zgmRf7dECEkmvFf9+3tNgatuO77jb2YDan2l3s494gRZSk/1hhw1FGnE8ZygPuHF5kIvWoKbrBh6nD+EXNHPaOPcKE2HVsF5lHHRV4ew6iJImQYEFyPM/Xf4ePUgfTuRPNz6RclAdnnMNzbx/Nsfs/wnEHPET3yo3E6z9rdSqN1VFbX8602cfw2GunsXzdkBxGnF+2bO3CVdddwM47LuGrk55j3H7vEImkSCS8Q72Zo6y0ntXrevHIM+P5z8sHUV3T9rF3xeLjTyv45g9GcsA+mznl2NWMGl5Dff1nrU6RCJSUOOZ9VMED/+rPf9/uHvpzsCR/KWGSJhjvsS/vuX0xUmzPEgawggiOTfRkETspSWpGgnJmJs5gZuIMosQZGJlDV1tHykXY4Iaw1u2MUwNvkzZU9eXu5y/g7ucvoGv5ZoZu9xHlpTXU1Zfy6ZphbKzSFX1zPlo8hN/ffB6/v9nRr88GBm+3mmg0ydbqCj5Zsj21Lez27ExSznjtrR689lYPIhHHDoNq6d0jgRms2xjj02XlSpI6KSVMEsgRYRk7sqwTPLm7PSQpY2lqn1yHUbCqarvz/iLtv9Yx1qzrzZp1Gl/TGqmUsWhJBYuW5DoSyQe6xBUREREJoIRJREREJIASJhEREZEASphEREREAihhEhEREQmghElEREQkgBImERERkQBKmEREREQCKGESERERCaCESURERCSAEiYRERGRAEqYRERERAIoYRIREREJoIRJREREJIASJhEREZEASphEREREAsSyWcjMFgFbgCSQcM6Nbc+gRMLS687puQ5BRESKQFYJk2+Cc25tu0UiIiIikqfUJSciIiISwJxzwQuZfQJsABxws3PuloDlgwsVCcGUMU/kOoSiNmXW8bkOQUSkI8wKGm6UbcI0yDm3zMz6A88ClzrnXspY5kLgQv/f0cD7rYu50+sLqOuz9bT/2kb7r/W079pG+69ttP/aZqRzrltzC2SVMH3uBWZTgCrn3P81s8xMDQxvHe27ttH+axvtv9bTvmsb7b+20f5rm2z2X+AYJjPrYmbdGv4GjkKtRyIiItKJZHOX3ADgETNrWH6qc+6Zdo1KREREJI8EJkzOuY+BvVpYbrODwqVZ2ndto/3XNtp/rad91zbaf22j/dc2gfuvxWOYRERERDobPYdJREREJECoCZOZTTKz+Wa20Mx+HGbZxc7Mbjez1WamAfWtYGZDzOwFM5tjZh+Y2eRcx1QozKzczN4ws3f8ffeLXMdUiMwsamazzexfuY6l0JjZIjN7z8zeNrOZuY6nkJhZTzN70MzmmdlcMzso1zEVCjMb6de5hp/NZvadJpcPq0vOzKLAAuBIYCnwJnCGc25OKCsocmZ2KFAF3OWcG53reAqNmQ0EBjrn3vLv6pwFnKT6F8y8Ozq6OOeqzKwEmAFMds69nuPQCoqZfQ8YC3R3zh2X63gKif99pWP19VstZ2Z3Ai875241s1Kg0jm3McdhFRw/h1kGHOCcW9zYMmG2MO0PLHTOfeycqwPuBU4Msfyi5j8IdH2u4yhUzrkVzrm3/L+3AHOBQbmNqjA4T5X/b4n/o8GNLWBmg4FjgVtzHYt0HmbWAzgUuA3AOVenZKnVjgA+aipZgnATpkHAkrT/l6ITluSAmQ0F9gH+m+NQCobfnfQ2sBp41jmnfdcyfwZ+CKRyHEehcsB/zGyW/60Rkp1hwBrg73538K3+8xKl5U4H7mluAQ36lqJiZl2Bh4DvOOc25zqeQuGcSzrn9gYGA/ubmbqFs2RmxwGrnXOzch1LARvnnNsXOBq42B+iIMFiwL7ATc65fYCtgMYPt5DflXkC8EBzy4WZMC0DhqT9P9ifJtIh/PE3DwH/dM49nOt4CpHfnP8CMCnHoRSSg4ET/HE49wKHm9nduQ2psDjnlvm/VwOP4A3xkGBLgaVpLcIP4iVQ0jJHA28551Y1t1CYCdObwAgzG+Zna6cDj4dYvkiT/IHLtwFznXN/zHU8hcTM+plZT//vCrwbN+blNKgC4py73Dk32Dk3FO+497xz7uwch1Uw9PVbreecWwksMbOR/qQjAN3o0nJnENAdB9l9NUpWnHMJM7sE+DcQBW53zn0QVvnFzszuAcYDfc1sKfBz59xtuY2qoBwMnAO854/FAbjCOfdU7kIqGAOBO/27RCLA/c453RovHUVfv9U2lwL/9BsqPga+nuN4CoqfpB8JXBS4rJ70LSIiItI8DfoWERERCaCESURERCSAEiYRERGRAEqYRERERAIoYRIREREJoIRJREREJIASJhEREZEASphEREREAvx/X19odWDRDgcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_locations = np.vstack(history_of_locs).astype(float) # create a matrix containing the agent's Y/X locations over time (each coordinate in one row of the matrix)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6)) \n",
    "\n",
    "# create the grid visualization\n",
    "X, Y = np.meshgrid(np.arange(grid_dims[1]+1), np.arange(grid_dims[0]+1))\n",
    "h = ax.pcolormesh(X, Y, np.ones(grid_dims), edgecolors='k', vmin = 0, vmax = 30, linewidth=3, cmap = 'coolwarm')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# get generative process global parameters (the locations of the Cues, the reward condition, etc.)\n",
    "cue1_loc, cue2_loc, reward_condition = my_env.cue1_loc, my_env.cue2_loc, my_env.reward_condition\n",
    "reward_top = ax.add_patch(patches.Rectangle((reward_locations[0][1],reward_locations[0][0]),1.0,1.0,linewidth=5,edgecolor=[0.5, 0.5, 0.5],facecolor='none'))\n",
    "reward_bottom = ax.add_patch(patches.Rectangle((reward_locations[1][1],reward_locations[1][0]),1.0,1.0,linewidth=5,edgecolor=[0.5, 0.5, 0.5],facecolor='none'))\n",
    "reward_loc = reward_locations[0] if reward_condition == \"TOP\" else reward_locations[1]\n",
    "\n",
    "if reward_condition == \"TOP\":\n",
    "    reward_top.set_edgecolor('g')\n",
    "    reward_top.set_facecolor('g')\n",
    "    reward_bottom.set_edgecolor([0.7, 0.2, 0.2])\n",
    "    reward_bottom.set_facecolor([0.7, 0.2, 0.2])\n",
    "elif reward_condition == \"BOTTOM\":\n",
    "    reward_bottom.set_edgecolor('g')\n",
    "    reward_bottom.set_facecolor('g')\n",
    "    reward_top.set_edgecolor([0.7, 0.2, 0.2])\n",
    "    reward_top.set_facecolor([0.7, 0.2, 0.2])\n",
    "reward_top.set_zorder(1)\n",
    "reward_bottom.set_zorder(1)\n",
    "\n",
    "text_offsets = [0.4, 0.6]\n",
    "cue_grid = np.ones(grid_dims)\n",
    "cue_grid[cue1_loc[0],cue1_loc[1]] = 15.0\n",
    "for ii, loc_ii in enumerate(cue2_locations):\n",
    "  row_coord, column_coord = loc_ii\n",
    "  cue_grid[row_coord, column_coord] = 5.0\n",
    "  ax.text(column_coord+text_offsets[0], row_coord+text_offsets[1], cue2_loc_names[ii], fontsize = 15, color='k')\n",
    "  \n",
    "h.set_array(cue_grid.ravel())\n",
    "\n",
    "cue1_rect = ax.add_patch(patches.Rectangle((cue1_loc[1],cue1_loc[0]),1.0,1.0,linewidth=8,edgecolor=[0.5, 0.2, 0.7],facecolor='none'))\n",
    "cue2_rect = ax.add_patch(patches.Rectangle((cue2_loc[1],cue2_loc[0]),1.0,1.0,linewidth=8,edgecolor=[0.5, 0.2, 0.7],facecolor='none'))\n",
    "\n",
    "ax.plot(all_locations[:,1]+0.5,all_locations[:,0]+0.5, 'r', zorder = 2)\n",
    "\n",
    "temporal_colormap = cm.hot(np.linspace(0,1,T+1))\n",
    "dots = ax.scatter(all_locations[:,1]+0.5,all_locations[:,0]+0.5, 450, c = temporal_colormap, zorder=3)\n",
    "\n",
    "ax.set_title(f\"Cue 1 located at {cue2_loc}, Cue 2 located at {cue2_loc}, Cheese on {reward_condition}\", fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with different environmental structure\n",
    "\n",
    "Try changing around the locations of the rewards, the cues, the agent's beliefs, etc. For example, below we'll change the location of the rewards, both in the generative model and the generative process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of the reward conditions and their locations\n",
    "reward_conditions = [\"LEFT\", \"RIGHT\"]\n",
    "reward_locations = [(2, 2), (2, 4)] # DIFFERENT REWARD LOCATIONS\n",
    "\n",
    "## reset `A[3]`, the reward observation model\n",
    "\n",
    "A[3] = np.zeros([num_obs[3]] + num_states)\n",
    "# make the reward observation depend on the location (being at reward location) and the reward condition\n",
    "A[3][0,:,:,:] = 1.0 # default makes Null the most likely observation everywhere\n",
    "\n",
    "rew_top_idx = loc_list.index(reward_locations[0]) # linear index of the location of the \"TOP\" reward location\n",
    "rew_bott_idx = loc_list.index(reward_locations[1]) # linear index of the location of the \"BOTTOM\" reward location\n",
    "\n",
    "# fill out the contingencies when the agent is in the \"TOP\" reward location\n",
    "A[3][0,rew_top_idx,:,:] = 0.0\n",
    "A[3][1,rew_top_idx,:,0] = 1.0\n",
    "A[3][2,rew_top_idx,:,1] = 1.0\n",
    "\n",
    "# fill out the contingencies when the agent is in the \"BOTTOM\" reward location\n",
    "A[3][0,rew_bott_idx,:,:] = 0.0\n",
    "A[3][1,rew_bott_idx,:,1] = 1.0\n",
    "A[3][2,rew_bott_idx,:,0] = 1.0\n",
    "\n",
    "class GridWorldEnv():\n",
    "    \n",
    "    def __init__(self,starting_loc = (4,0), cue1_loc = (2, 0), cue2 = 'L1', reward_condition = 'LEFT'):\n",
    "\n",
    "        self.init_loc = starting_loc\n",
    "        self.current_location = self.init_loc\n",
    "\n",
    "        self.cue1_loc = cue1_loc\n",
    "        self.cue2_name = cue2\n",
    "        self.cue2_loc_names = ['L1', 'L2', 'L3', 'L4']\n",
    "        self.cue2_loc = cue2_locations[self.cue2_loc_names.index(self.cue2_name)]\n",
    "\n",
    "        self.reward_condition = reward_condition\n",
    "        print(f'Starting location is {self.init_loc}, Reward condition is {self.reward_condition}, cue is located in {self.cue2_name}')\n",
    "    \n",
    "    def step(self,action_label):\n",
    "\n",
    "        (Y, X) = self.current_location\n",
    "\n",
    "        if action_label == \"UP\": \n",
    "          \n",
    "          Y_new = Y - 1 if Y > 0 else Y\n",
    "          X_new = X\n",
    "\n",
    "        elif action_label == \"DOWN\": \n",
    "\n",
    "          Y_new = Y + 1 if Y < (grid_dims[0]-1) else Y\n",
    "          X_new = X\n",
    "\n",
    "        elif action_label == \"LEFT\": \n",
    "          Y_new = Y\n",
    "          X_new = X - 1 if X > 0 else X\n",
    "\n",
    "        elif action_label == \"RIGHT\": \n",
    "          Y_new = Y\n",
    "          X_new = X +1 if X < (grid_dims[1]-1) else X\n",
    "\n",
    "        elif action_label == \"STAY\":\n",
    "          Y_new, X_new = Y, X \n",
    "        \n",
    "        self.current_location = (Y_new, X_new) # store the new grid location\n",
    "\n",
    "        loc_obs = self.current_location # agent always directly observes the grid location they're in \n",
    "\n",
    "        if self.current_location == self.cue1_loc:\n",
    "          cue1_obs = self.cue2_name\n",
    "        else:\n",
    "          cue1_obs = 'Null'\n",
    "\n",
    "        if self.current_location == self.cue2_loc:\n",
    "          cue2_obs = cue2_names[reward_conditions.index(self.reward_condition)+1]\n",
    "        else:\n",
    "          cue2_obs = 'Null'\n",
    "        \n",
    "        # @NOTE: here we use the same variable `reward_locations` to create both the agent's generative model (the `A` matrix) as well as the generative process. \n",
    "        # This is just for simplicity, but it's not necessary -  you could have the agent believe that the Cheese/Shock are actually stored in arbitrary, incorrect locations.\n",
    "\n",
    "        if self.current_location == reward_locations[0]:\n",
    "          if self.reward_condition == 'LEFT':\n",
    "            reward_obs = 'Cheese'\n",
    "          else:\n",
    "            reward_obs = 'Shock'\n",
    "        elif self.current_location == reward_locations[1]:\n",
    "          if self.reward_condition == 'RIGHT':\n",
    "            reward_obs = 'Cheese'\n",
    "          else:\n",
    "            reward_obs = 'Shock'\n",
    "        else:\n",
    "          reward_obs = 'Null'\n",
    "\n",
    "        return loc_obs, cue1_obs, cue2_obs, reward_obs\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_location = self.init_loc\n",
    "        print(f'Re-initialized location to {self.init_loc}')\n",
    "        loc_obs = self.current_location\n",
    "        cue1_obs = 'Null'\n",
    "        cue2_obs = 'Null'\n",
    "        reward_obs = 'Null'\n",
    "\n",
    "        return loc_obs, cue1_obs, cue2_obs, reward_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting location is (0, 0), Reward condition is RIGHT, cue is located in L1\n",
      "Re-initialized location to (0, 0)\n",
      "Action at time 0: DOWN\n",
      "Grid location at time 0: (1, 0)\n",
      "Reward at time 0: Null\n",
      "Action at time 1: DOWN\n",
      "Grid location at time 1: (2, 0)\n",
      "Reward at time 1: Null\n",
      "Action at time 2: UP\n",
      "Grid location at time 2: (1, 0)\n",
      "Reward at time 2: Null\n",
      "Action at time 3: RIGHT\n",
      "Grid location at time 3: (1, 1)\n",
      "Reward at time 3: Null\n",
      "Action at time 4: UP\n",
      "Grid location at time 4: (0, 1)\n",
      "Reward at time 4: Null\n",
      "Action at time 5: RIGHT\n",
      "Grid location at time 5: (0, 2)\n",
      "Reward at time 5: Null\n",
      "Action at time 6: RIGHT\n",
      "Grid location at time 6: (0, 3)\n",
      "Reward at time 6: Null\n",
      "Action at time 7: DOWN\n",
      "Grid location at time 7: (1, 3)\n",
      "Reward at time 7: Null\n",
      "Action at time 8: DOWN\n",
      "Grid location at time 8: (2, 3)\n",
      "Reward at time 8: Null\n",
      "Action at time 9: RIGHT\n",
      "Grid location at time 9: (2, 4)\n",
      "Reward at time 9: Cheese\n"
     ]
    }
   ],
   "source": [
    "my_agent = Agent(A = A, B = B, C = C, D = D, policy_len = 4)\n",
    "\n",
    "my_env = GridWorldEnv(starting_loc = (0,0), cue1_loc = (2, 0), cue2 = 'L1', reward_condition = 'RIGHT')\n",
    "\n",
    "loc_obs, cue1_obs, cue2_obs, reward_obs = my_env.reset()\n",
    "\n",
    "history_of_locs = [loc_obs]\n",
    "obs = [loc_list.index(loc_obs), cue1_names.index(cue1_obs), cue2_names.index(cue2_obs), reward_names.index(reward_obs)]\n",
    "\n",
    "T = 10 # number of total timesteps\n",
    "\n",
    "for t in range(T):\n",
    "\n",
    "    qs = my_agent.infer_states(obs)\n",
    "    \n",
    "    my_agent.infer_policies()\n",
    "    chosen_action_id = my_agent.sample_action()\n",
    "\n",
    "    movement_id = int(chosen_action_id[0])\n",
    "\n",
    "    choice_action = actions[movement_id]\n",
    "\n",
    "    print(f'Action at time {t}: {choice_action}')\n",
    "\n",
    "    loc_obs, cue1_obs, cue2_obs, reward_obs = my_env.step(choice_action)\n",
    "\n",
    "    obs = [loc_list.index(loc_obs), cue1_names.index(cue1_obs), cue2_names.index(cue2_obs), reward_names.index(reward_obs)]\n",
    "\n",
    "    history_of_locs.append(loc_obs)\n",
    "\n",
    "    print(f'Grid location at time {t}: {loc_obs}')\n",
    "\n",
    "    print(f'Reward at time {t}: {reward_obs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Cue 1 located at (0, 2), Cue 2 located at (0, 2), Cheese on RIGHT')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkwAAAF3CAYAAABXMRQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABCBklEQVR4nO3dd5wcdf3H8ddn93p6JSGFhISEGoiJgZAAARIMGIoF6cUGPxGIioqASlRERZH+UxApisiP3kGJJEE6CR1SCKRX0sv13e/vj5kjm83eze7d3G259/PxuMfdzc585zOz3535zPf7nVlzziEiIiIijYtkOwARERGRXKeESURERCSAEiYRERGRAEqYRERERAIoYRIREREJoIRJREREJIASJhEREZEAeZMwmdlYM7vfzFaaWa2ZrTez58zsHDOLtnEsPzCzJ8xslZk5M5uWwbIzzWxm60WXVgzTzOyoVig3o30RUNZJZvaDDJcZZWaVZtYvRVlvmVm1mS0xs582t86Y2VfN7CG/nCozm29mvzGzTinWucbMOjZnPQnlFJvZBWb2kpltMrMaM1tkZneY2edaUnYzYklr2xtZdoJfPya0fqRNxjDNzEI97vllhvJAOzPr6peX0XtrZo+b2c1J07qZ2e1mts7MtpvZdDM7oJlx9fXf69l+PfzUzP5jZocnzWf+Z+3HzVlPUln7mtmdfn2rMbPNZvZfM7vYzMr8eRrq1cSWrq+98c9FLuFnq3+cOSHFvHeZ2fIU0zua2U/M7A0z2+Kfm5ea2QNmdqKZWcK80/z1FKUoZ6j/2rn+/y6Nn8Xh7pFgeZEwmdn3gJeA7sClwETgG8AC4E/AlDYO6dtAb+DRNl5vWK4EQk+YQnYSkFHCBPweuMM5t6Jhgpl9AXgIeAM4FrgB+ClwdTPj+iEQAy4HJuPVv+8AzyWdiB8DVgE/auZ6MLMOwH+Aa4HXgTOAY4CrgMH+a20p3W3PVRPw6n4ux9oVL8a0EyY/aTkG+E3CNAOewHufLgK+AhQDM8ysfzPiGgWcglevTwbOBaqBmWb22fHXeU9C/iVwmZl1b8Z6GuI/GXgL2B/4Fd72nQa8DPwCOL+5ZctO3gXG+j/fBDoAD5vZwUELmndh+jreOfk5vPoxCa/+dsA7P45pZlxjk35WA/9KmvalZpbdfM65nP4BDgfiwI2NvD4EGNHGMUX830WAA6ZlsOxMYGaW96kDrmqlctPeFwFl3QUsz2D+Uf7690ua/hYwK2naz4FaoE8z4uqVYtrZ/rqPSpp+AbAeKGvmPrgdqAHGNvL6l9q43qS97Snmm+DPN6EtY06KYZofQ1FrlBtSWYP8GL+VwTJPAA8kTTvRL+fIhGldgA2NHUsD1tE1eb/5x7/5wAtJ06N4Fws/buY+2AuoAh5J9V4BvYBxSfVqYrbqVb7++OeiF5Om9ffPt39Omr7L8dhffh0wpJHyJwJ7J/zf6OcPGOq/dm4jZS0G7sn2PsvlK60Gl+J9yFM28TrnPnbOvQuNN437zYmLk6ZVmNnv/O6NWv/3FelcKTvn4s3akkaY2XAze8Rv6q4ys1fNbHKK+Q7051uf0CVyWcLrx5jZ0+Z1FVaa2ftmdokldD8l7J8rEpo2pyW8foTf1L7Vb8b/l5ntnxRH1MyuSljPTDPbL81t7WVmt5rZAn/ZZWZ2ryV0o5nZXcA5QL8Mml+/BbzrnPsgoZwBwEHAPUnz/h3vavvYdGJO5Jz7NMXkN/zf/ZKm3493ovlypusxs754++AvzrlXGonlkYT5F/v7LbmcXbpJ/Xr0uJlt9OvRS2Z2WFBMGW57IPN836/HtX59utnMOifNV2Rml5rZh+Z1q35qZs+a2d7+62Vmdp1f37eZ2Wrzusz3TihjGt6VL0BdQ71KeD2t44GZjTSvW6jazFaY2c8AIw1mdqqZPe/Hv828rqtzEl4fBCzy//1LQt0/t4kyd8erx/cmvXQCsNI5N6NhgnNuM15ydWI68SZyzm1yztUnTasH3ibpvXfOxYAH8D6TzfE9vGTsguR1+uV/6px7KWlyhV931vk/95hZ18QZ/Hp0mZnNM6+Lb6WZXWt+917CfIF1wbyuqJvM636qMbO15nV57p3p+lIxs87+9qz0l53vf1YSu7gauiNPCNr2dDnnlgOfAgMD4jsEOAL4tXPu40bKmu6cm9ecOHLVLn2JucS8E/2RwKPOueoQyy3Ca97bF6+59z3gEOBneN1+l4S1rjRi2R14EdgKXAhsBr4LPGVmU5xzz/jzjcHL6BcC3weW412JjUgobk+8bpqb8JrLR+Nl9b2An/jzjAVewbtiuNWfttxfxxfxmtyfAs70X7sU+K+ZjXDOLfOnTcPrlvkj8G9/PY+nucnd/dguw/tg7o63v18ys7399/lXfsyfxzvwg9fS0pTJftyJGpK49xMnOucWmVkl3vsfhiP833OT1rPOzOb6sSWf0IIciff5THe/psW8sTH/xWt5+zZQCfwPMN3MDnXOzcmwyJTbnqZf49WDW/BO5A2fxwPN7IiEC5P78LporwemA2V4Lc99gXlAKdAJr6tyFV4duwB4xcz2cc6txmut64/X7TAer2sRSP94YGY9gefxugfOwauTPyLg5JJgT+BB4Ld4V/GHA7ebWblz7s9+7F8GHsbrXmt471OekHyT8Fp0/ps0fT+S6r3vA+BsM+vonNuWZtwpmVkJ3vHk3RQvvwBcZGZ7Ouc+ybDoScAbzrlVGSxzA/AkcDowHLgG7z0+J2Gee4Djgd/hde3tg/d+D8Lrsszk3HAd3rHpcuAjoAcwDu8CKe31peInZk/hdcv+3I/hi3jH217+OjPd9rSYNx6xB03XOYCj/d9PZroOIJqQ9302rRnltL1sN3E19QPshtdM95s0559GiqZxvORgccL/Z/nlHp403xV4XTW901xfi7vkgD8A9cDQhGlRvKbuNxOmvQAsAyrSXI/58V0BbMTvRvRfS9klh5eM/SdpWme8Ztfr/f+7AdvYtcn20kz3RcK2DvCX/VLC9LtIs0suoZ58O2n66f70vVMssxz4awh1tB+wFniukdf/DixoRrkN+3N4mvMvBu5KMX2n9wQvoZ4LlCS9B3PxLkxC2/akeSeQ0CWHd/KpSY4ZL1F3wAn+/0f5/1+cYZ2qwLsI+X7C9Gmk6BIgzeMBXoJXCwxImKeD//lwGe67iP/5/AvwTsL0QWTQJYc3jmxFiukLgPtSTP+WX/6ATOJtZN1X4yV+h6V4bYi/ntObUW4V8M80522oV3cnTb8Z78LM/P8P8+c7O2m+M/zpB2VYF94H/thEXGmtr5Flp5Cie4odXfQ9M9n2JtYzE+9ivcj/GYzXMrgW2DNp3rtIOB779c4BpY3U64afxPPONH+Zpn7ObSTWxahLLmsmA0uAl/1m0yL/yuLfeF01h7RhLIcDrzrnFjZMcF6T9j+Bg/ym2Qq8q5d/OOcqGyvIvDtZbjWzJXgf7jq8q+6ueIPUG2Vme+Ed5P6RtE8q8VqkGu6GOQDvJHF/UhH3pbvBZvYdM3vHzLbhJYtL/ZeGp1tGkt3936m6jFqNeXfAPYa3DV9vZLaGVrSsM7NyvBahB4B4wntseC03hze1fFJZ6Wx7Uw4BSti1u/Q+v8yGlqtj8A6kfwmI52tm9pqZbfKX3w50JL06le7xYCzeZ7WhpRXn3Ha81rFAZraXmf3TzFbgfTbr8BKY5tZ78OpWm9Z7ADM7Ha/V+lfOueTWLdgRU1vV/eTW5ffwWh538/+fjHdMfDDFeww76n66deEN4Fwzu9zMRtuud92mu75UGsbtJrdK34P3mRmb4bY3ZRw76uIneC1iX3GZtwo2+N+E8urwbgBIdghe70HiT9sP4G6GnO6SwxswWwXsEXK5vf0y6xp5vUfI62tKd7zukWSr8U5k3fBOABH8rrNU/Gbcx/EOUNPwuiqq8LoyrsDrxmhKQ0L1V/8nWUNS09f/vSbp9eT/G4vzIuBGvOblH+G3fgGvphFjYxqWS+622+j/7pZimW54Y+OaxU8+nsDrZjnCeX3/qVTRvO1qOCnvgdfaGIbueK0vP/N/dmFmERcwRi+DbQ+KBbxuqM845+rNbH3C6z2ADc65qibiOR74P+BuvDuo1uGdcJ4mvX2f7vGgL6m7uQLrvp9gPod3AfITvC6PWry7DL+RRoyNKSN1d/VGUtf77gmvN4u/v+/Ca6G9spHZGt6v8masYhmZH/OTP8sN+6Th/e+Nl2xsb2T5HgnzpVMXLsI7Rn8Dr+Vxg5n9DbjCv6hNd32pdMer87VJ01cnvJ4oaNub8g5e0h7F68b9HfCAmR3gUo9ZbNDwmR+I1yXZ4Gq8ljDYMb4x2RyXNDbNv9DJeTmdMPkHz5nAJDMrdc4FjWOpBq9vPamyJVfO9XiDK7/WSDmLmxFuc20A+qSY3gfvynojXsIUp+mBtUPwxhKd5Zz77KrdP7ilY73/+zK81oZkDfuz4QS3G954CBL+T8epeN1+n40TM7PBaS7bmIbYk08QDfHth9dK1rC+QXhdNh82Z2VmVow3FmU0MMk5914Ts3dPiC8TM/HGIRzPjqvSplTjHaAT40yu95vw6tEtwN9SFZJGspTJtjel4SDfh4R65F+F90h4fR3Q3R/n01jSdCqw0Dl3blKc6d7Wnu7xYBWp63k6dX8s3on4MOfciwlxtvQYvB6vKyXZB3itc8n2BZa6Zo5fMrOj8VooH6HpW/sb9v26ZqxmOvAtM+vjvPFnYViP9xlp7OaGlQnzBdYFf/9dhvf4hD2Ar+KNTavF605Pd32pbMCr88nnsT4Jr4dlm3Nutv/3a2a2CG+c3jS8sbSNed7/PQVvPBcAzrml+BfXKcYp5b186JL7Ld4B9JpUL5rZYDNrGPi8xP+9f8LrXYFDkxZ7Fm/czDbn3OwUP835kDfXLOAQ/yQOfDbY/RTgLefcFv+K5UXgTP/qPpUK//dnV0b+SeOMFPPWsuuV33y8g8F+jeyThoGd7+JdNSUfUE4N2M7EOJOv3lJ16dSkiLExi/EOTnsmTvQ/vO+w6z4404/hmTTL/4zfkvcPvLE1JznnXg1YZDDNaCFyzq3Eu4o/z8ySm+AbYjkp4d8lJNR73xeTytyONzj4QLzxcbu8z03F1Ixtb8qrePUwud6cgnchN9P//994La1N3XFVgXdRkegsdh1I2nDBlVyv0j0evIL3WR3QsKB5z8pK56Ik1eezG7vesdZYjI2ZBwxIkXg9jneXaUPXJubdfXg8zbyRwK+Hj+GNgzszILluSOKa0zp6Hd7Fwv+m6OrCzHqa2bgMy3wWr8WlSyPv8cqE+TI6NzjnljjnrsXrCts/w/WlMgvv3Hxy0vQz8D4zKe+aDYPz7qp8BC9hbfR5Xc67c/e/eHdbD2mteHJOtgdRpfODd5tpHK9J+wy8rP0EvLsDtgMn+vN1xbuKnoOX+X4FeA3vZLI4obxivEq5Au/hiEfj3Zp7Id4BusmB1XhX11/FSxoc3nier/o/QcvOZOdB3w1jED7CG6Q8Ba8rIQZMTpjv83jN+W/jnQyOxLvj5yb/9RK8xGGhH8eJ7LirzgGDEsp6C+9AO8nflt396cfhHdD/z993R/jbeD3wg4Tlf+W/H7/3y7gcr4shcNA33t0/cX+ZiXhNuAuSlwWm+tO+42/7AWns18dTTD/OX9+teIMkv4+XXP0+ab5zSeM5QewY7HgVXl984k//pHkN72rwqhSxLm5qPf58HfEG+1fidWEehze+4Vy8z8LGhHm/7sd1HV59/gFecpu8Xz+HN2j/Obxk5Qj/vf418Nuwtj3FshOS96//3ju/fh3jv+db8Q7EiYNFH/Tr5TV4Y0OO9+veBP/185O2/VK8LoONJAwqZ8eziaYBBwOjMzkeAD39MufiJXYn4T1QdxkBg77x7m7aDMzGS2S/5r8/CxOXxTtRrvPLPQLv89kjjf36uaTpEbw7s5b57/MX/Hq3gaQB33jHjZkB8e/tL7vYX+dO73+K+afindwrUsR6bhp1/2S85PENvOPc4f57cjVe683UpDInJi1/Lrse9+7137+f+ftjEt6doo8AwzKsC6/gtTBNYccDUWMNcaW7vka2PYL3GdiKd+6bhFe3HXB1iv0ZuO2NrGcmSc9h8qcfgHfMvClh2l3s+hym/ngJ8Ua848dkvHPzl4E/+zFcmjD/NPL8OUxZXXlGgXqtRA/gNYvX4X14/43XWpB4cB3vf8gq8U7EZ5J0l5w/Xxk7xvrU+OW94U9r8sF2fnmukZ90KunMpGnD8Z6KuhnvZP4qCclSwnwj8caObMIbIzAvqUIehNcSVYl3wvglO+6KGZQw3zi8pLKaXU+oY/FuFd3ov74YbyDu2IR5ongnzdV+HDPxmvrTSZjK8U68n+IdEJ7EuxpNjqMD3sD3jf5riwPK/Q5eItAhxWtfxmtpqsFrLv45EE2a57v+evYJWM/iJt77aUnzjvOn7580/Q28wcPp1PtiP7aXgS14J6FFeOMERiTMF/G3a4n//v+LHXcqJce1j/+ervX3yXK8Vofjwtr2FMtOYNeEyfAS2Pn+dq3C6y7snLRsw92eC/z5PsW7qBiesO1X4XVzVOKd8EaSdOegX29v8bc7zs6JSlrHA7yE8794n40VeCfDXySW1cQ+OArvYqUK7wLjYlLc2YuXiH2Id5xrMsHwt2kFcGWK17oDd/jbUonXMnRgivk+JcUddUnznNvEe7/LtuMl5A8mTfuiP/8ux7ZG1rkf3rF2qf++b/b3/QX4d2eRWcIUwUvk3vHfv83+39fgtQSlXRfwxvq85ZexHa916eKkGNJaXyPb3hnvbrdV/rYvwPusWMI8aW97I+uYSYqEyX/tXr+e9vX/v4sUdy3jPc7jcrzzyVY/1qV45+rjk+adRp4nTA23XIrkNb+7YTnew+6S77xKZ/l7ga7OueNCjOlPeMnSYQnTOuAlvGc455LvNBTJmHkP5TwDr9UiowO6mQ3DS1gPds69HlI8u+O1bB3jnPtPwvSr8XoGDsg0TpFckNYYJjObbN6TRhea2U+ClxBpW865LXhXfT+25o02PByvlSIUZtYH78FxVyS9dCheN8yDYa1L2r3r8IYjNPowxCYcgfccrVCSJd+P8L6OKPm7Do/A61JSsiR5KbCFyR90twCvH3U5XtPkac65Zt1hJNJa/AHxPwJud00PqmyLWA4BRjrn/pTNOKR9MO+rlLo75zJ9onzYcRje11g97pxrztPfRXJWOgnTWLzxCV/w/78MwDn3myYXFBERESkQ6XTJ9WPHQ/TAa2XK+Is2RURERPJVaA+uNLPzgPP8f0eFVa5IU/pWDM12CAVtVeXC4JlERPLfOudcr6ZmSCdhWoH3IK8G/f1pO3HO3QbcBmBmGtQnbeL8fa7LdggFbdqcdB8ULyKS15YEzZBOwvQGsJf/9RUr8B6Cdno6a594epMPDpYk0+8d/dnf2ndpmr8qeB5pNtXD9Oiz2zLafy2j/dcyifuvKYEJk/O+z+1CvAfhRYE7nHMfBCwmIiIiUjDSGsPknHsa78m6Inll4zkTsh1CTut298xshyAikhfy4ct3RURERLJKCZOIiIhIACVMIiIiIgGUMImIiIgEUMIkIiIiEkAJk4iIiEgAJUwiIiIiAZQwiYiIiARQwiQiIiISQAmTiIiISAAlTCIiIiIBlDCJiIiIBFDCJCIiIhJACZOIiIhIACVMIiIiIgGUMImIiIgEKMp2AK2tZvtq1i+dzuY1s6na/AnxWC2RojI6dBtOl91G02PgJIrLumY7zBzl2If3OMReYARv0pvVRHBsoQsfMoI33Rhe4QjqKc52oDkpSi37RZ9hePR5Bkdeo8I24Iiw0fXn49h4Pogdy+L4GMCyHWpO6lyxicMPmM5BQ95gaN/5lJVUU1dfzOI1Q3jnk1HMem8Sn27uk+0wRaSdKNiEqWrrMha9/hu2fPo2AC5eu9PrNduWs2nlSyx+8zq695/AoFGXUFLeIwuR5qYxvMgF9ge6s54Saoha/LPXevIpg9xCjrJniRPhfncW93MOscKtThmJUMdRxddzdPH1GHFK2EYkISfqxgoGRd7g8OI/s8X15pHaa/gwNjl7AeeYrh028J0pf2D8fjOJuwhlJdU7vd6n+ypGDn2dc4/5Ex8sPogbH/sJK9YPzFK0ItJeFGSX3Kr59/Hu06eyee1sXLx2l2SpQTxWjYvXsmHZDN5+4stsWDazTePMRaVUc7ldxs/sJ/Sz5ZRb1U7JUoOIQYVV0tG2cZrdyV/sFPqxJAsR55aetpBLyw9mUvEfKLctlNnOyVKDiMUpte30iizi3NKzOaf0bIqpbPuAc8yh+87krh9+ifH7z6CkuHaXZKlBaXEtpcW1HLjnbP588WmcNPa+No5URNqbgkuYlrx9E0vfvpl4rAbcrif6VJyrI1a/nY9evoI1Cx9t3QBzWCnVXGvf5lBmUWapT1SplFs1/VjKzXYOe/BxK0aY23azefygfAK9bCGlln7yU2JV7Bd9hovLvkAJ21sxwtx2zOce57JTrqBD2XZKiurSWiYajVNWUsM3Jt/MNyff2MoRikh7VlAJ09pPnmD1/P8jHkv/ZJ8oHqth8Zzfs2XtmyFHlh8ut8sZxMeUWuoWuaZEzFHBdv5g59OBra0QXW4rYzMXlU+mjC1EzGW8fIlVs1tkHmeXnht+cHlg/0FvcdGJ11BWUtOs5ctLqjlx7P0cM+rxkCMTEfEUTMJUU7mWRbOvaXay1CAeq2HBi5cRq68KKbL8cBjTGcnrzUqWGkTMUU4lF9tvQowsP3y15AeUsq1ZyVKDEqtmr+gLHBh9JMTIcl9ZcRU/Pe2yRrvf0lVeUs2Fx/+enp3XhBSZiMgOBZMwLXv3T8RjzT/ZJ6qv28bqBfeHUlY+MOJcaNdQnkE3XGNKrZZxzGIgn4QQWX7YzeYxouhxiq15rSOJSq2Sr5ZcghELIbL88MWDH6JD2bZQyioqquXcSX8KpSwRkUQFkTDV121j3ZJ/gwvnJONiNayady8uzTFQ+W40r1BGy5OlBlHq+Yr9I7Tyct0RxbcQpT608oqtin2iz4VWXi4zi3PyYfe0uHWpQXE0xhEjnqOiNJwETESkQUEkTFtWzyZi4d7SHquvpGpz+2glOdL+RUUGg5SDFFmM8cwIrbxcd2DRY0QtvISpzLYxMvpgaOXlsoG9FlFRGu5A91i8iJFD3gi1TBGRgkiYtq5/v1XGHG3bMC/0MnPRPrwXepllVNGVDaGXm2s68imlrXBn26Bo+zjhD+s/FxfygzvLSirZe8D7oZYpIlIQTxqs3LQQCLf7LF5fRfWW9vFcoV6sDb3MaH2Mq9+8kMrNHUMvO1GXyqbHrdXf2LVV11/Wbwv2tRiUhVtuj/giLrzx2HALTaFo9aYmXz9pWUmrrn+3ISspLwn3+VPRiGNwn49CLVNEpCBamFw8vO6QRPF4es+CyXeRkJNNAAdYpPl3jOWNFtwV12Sx7eTbUqzItcq2FkVb55ggIu1XQbQwFZd1C79Qi7ab75iropxiwk0Oa4vKuGbUL1nEXqGWm2z8/FVNvr7xnAmtuv6+9gFTSycSJdxBxlWRztx88TOhlplKt7tnNvn6i8P7tur6v7bb3Zxb/yeKi8JNcDZvb4Vjgoi0awXRwtSp5wgsWhpqmdGicjp02zvUMnPVYoaEXmYxtSxlcOjl5po1bhhFtPxxAslWxfcLvcxctHDlcGrqwu3PrK4t5YMlB4ZapohIYSRMvUZgIQ8cjcdq6dB9n1DLzFWz3SHUuHDHqixjULv4Mt44xayOh5tY17kS5seODLXMXLVg+b6UFIXz/LQGzkX4YMmIUMsUESmIhKmi6zBKKnqFWKLRpc8Yiku7hFhm7vo3x4daXqUr5yF3Rqhl5rJZ9d+l2nUIsUTjtfqzQywvd22r7sychQcTj4d3wbN+S08+XjU8tPJERKBAEiYzo/8B5xOJhtO0H4mW0n//b4ZSVj5YT29eZxy1rjiU8uopZiaTQikrH7xV/xVihNMlXO9KmBs7hs1u91DKywf3zvgmtfXh7L+qmnL+/vx5EHKLs4hIQSRMAD33+ILXhWbRFpVjkRJ6DppMp54HhBRZfrjRXUYdLe+Wq3Zl/M79ktqw77PPYfWUcU/NbdS68haXVUcp99fcEEJU+WPesv35z9uTqalrWdJUH4uycOVwnn97ckiRiYjsUDAJk5kxbNzVFJV0ptlXl1ZEaYe+DPrcD0KNLR9soju/dldT7Zp/0qpyZfybKbzO+BAjyw9zY1/g9fozqHEVzS6j1pXz95o72EaY3cv54c9PXsKajX2prW9eK2csbmyr6sSv77satS6JSGsomIQJoKSiFwcccyfFZd2xSGatJZFoGeWdBrD/pL8SLW7+SS+fvcE4fud+SbUrI+4yO+lUuzKeZzI3ux+3UnS576Haa5ldf0rGSVPcGbWunHtqbuPDWPtsHamuK+d7t97OynUDqK7NrHWypq6Ezdu7MfXPd7J+S+9WilBE2ruCSpgAyjr156ApD9FjwFHemCYL2EQrIhItpc+wkxlx7D/azbOXGvMiR/Nd9zeWMojKNLqYql0p21xHrnHTuN79FFd4VSptjggP1N7IP2puo8p1TquLrtp1YK0bxh+rZvFu7KTWDzKHba3sygU338OjL59CdW0pdfVN32UZi0Wori3jpQ+O5OvXPszK9QPaKFIRaY8K8r7vopKO7DXuKrZtmMfKufewYdnzWCRKeawGB9QUlePiMTCj1+Ap9B1+GuWdB2Y77JyxlD05393HWF7gFO5mL+ZSQxll9VVgUBUtp5RaNtGNh9zpPMuJbKdTtsPOGe/GTuSjyiMYU3QPE4pvppN9Sh1lGPHPvjethCqWxw9ket0P+CB2HPHC/ChmrC5Wwl//dRHPzj6Rkw69j2NGPUHEHPXxKOWxKnBQW1xKNBLjxQ8m8OB/z+Kjle3j8R8ikl0FfZTu2H1vho27ChePUbV1KSf/98fU4vi/Ay+kottQSjv0w9rLd1BkKE6UlziSl9yRlFDNED7ikrm/AOBP+/+Qj9ibLXTNbpA5rIquzKq/kFn1F9KBdfSLvEtHW4cjwgY3kJXxA6ij5YPEC9WK9QO55Ykfc8sTP6JPtxUM7rOQb350M67G+FWfa1i+biBx17IbPEREMlHQCVMDi0Sp6DKYI/2vUHluwITsBpRnailjLgewaXV3AObsf0iWI8ov2+nJgvhR2Q4jTxmrN/Zn9cb+fGX6vQAsnVj4T5AXkdzTfgeciIiIiKRJCZOIiIhIACVMIiIiIgGUMImIiIgEUMIkIiIiEkAJk4iIiEgAJUwiIiIiAZQwiYiIiARQwiQiIiISQAmTiIiISAAlTCIiIiIBlDCJiIiIBFDCJCIiIhJACZOIiIhIACVMIiIiIgGUMImIiIgEKAqawczuAKYAa51z+7d+SCLh6Xb3zGyHICIiBSCdFqa7gMmtHIeIiIhIzgpMmJxzLwAb2iAWERERkZxkzrngmcwGAU+m2yVnZsGFZsEM//eRWY0if+Xi/ps26olsh1DQps05PtshfCYX65+IFIw5zrnRTc0QOIYpXWZ2HnBeWOWJiIiI5IrQEibn3G3AbZC7LUwiIiIizRFawpTKxNNnt2bxGes23WsAmzjxtixHktr0e3e0BubavoMc3X/zV2U7goI29cat2Q7hM/1vPBaAqRc/k+VIdnXDxZ0++zsXP7u5LtePfblO+69lEvdfUwIHfZvZP4FXgOFmttzMvtnC2ERERETySmALk3PutLYIRKQ5Xhze97O/dZXVMon7L5dalkREcoGe9C0iIiISQAmTiIiISAAlTCIiIiIBlDCJiIiIBFDCJCIiIhJACZOIiIhIACVMIiIiIgGUMImIiIgEUMIkIiIiEkAJk4iIiEgAJUwiIiIiAZQwiYiIiARQwiQiIiISQAmTiIiISAAlTCIiIiIBlDCJiIiIBCjKdgCtzeL1DPzkKQauepkl6z4gQpyTnzyZ5d33YUm/w1g54GiIKG9sTFl9JftvfpthWz5kAIsxHN9ecD0LuuzL+10OYn1Z72yHKAXL0bfHJ+zRZx4Dei1gt8F1xKuM8b0fZdmaYSxdszdO13wi0kYKNmEqqt3CES/9lMNXvUKxf1gt8V/bY8siarYsgsVPs82i/GePybw25gpcUUlTRbYrvapXc8ai2zl69TPErIiSeA3FVg/AV5f9g6qV5RS5ej7sMoK/DT6f97uNzHLEUijMYozZ+19M+vy9dKrYCA5KS6rhAADHCXW3EndR6upLmfnWV3nhnS9TFyvNdtgiUuAKMmEa+PHjnPv6VVS4OI2lQA2H11IX48TFTzF+6XPcffgf+XT3Q9oqzNzkHMeufITvLPgjRfE6iokBNTvNEsHRIVYJwMiNs9ln8/vM3G0Stwz7EdVFFVkIWgpFzy4rOPfYX9CrywovSUqhpLgWgLKSKr4w5u+MH/EYdz1zJUvW7NOWoYpIO1Nw7dn7v3MLF7z2S7o2kSwlKwX6xGv5/swLGfjJE60ZXm5zjovm/47vLPgj5fFqP1kKVhav5sg1/+LG2efSoW5rKwcphWpA7/n88NT/oW+PRY0mS8lKimvo1ulTvvulS9h/8EutHKGItGcFlTAN+uhhzvzgzrQTpUQRoAz4n1d/QY81b4YcWX44c9FfmLTqScrj6Z2sEpXGa+lXuYxr3voOkXh9K0Qnhax7p9VccNIPKSupJBqJZ7x8SXENZ3/h1wzq80ErRCciUkAJU3H1Js5547fNSpZ2Kgc4a+bFWDs76Q/ZOo9Tl9zdrGSpQYmrY8D2xZyy5G8hRiaFzohzzuRfUVLc/LoHXtL09WN/QXFRy8oREUmlYBKmo168lHIyvzJNFgV2i1Uz8s3rWh5UHvnRh7+gOF4TPGOA8ng1Zyz+K11r1ocQlbQHB+01iz7dFzerZSlZeelWjvrcfSFEJSKys4JImCL11Ry2dk6LW5calAJHL3wkpNJy35Ct8+hXuSy8yuBgyoqHwypNCtzEUfemPWYpSElxLYcf+CiRSPtqIRaR1lcQCdPQBQ+EviE947V0+/SdkEvNTcesfJLieG1o5ZW6Go5d2X4STmm+rh3X0Kvb8lDLjFiMIbu/G2qZIiIFkTANWP166M9HiAEDl80IudTcNGLTm0RD6M5M1L12A+X120MtUwrPwN3mE4uF++ktLqplj93mhVqmiEhBPIdpj00fhb4hJcD4hY9w1oYPQy65cRsT/u42/bw2W+9gFoKFW2ZNpJQBlYtZ0Hm/cAuWgtKn+xJKi6tCLbMoWs9AJUwiErKCaGEqCbE7qUEEwIXb6pKrDBd6mc6MspjuVpKmlRRXEYmEX//CTsJERAqihakmEv5XmsSBhT325ZaJt4ZedmOm3zv6s78nTrytzdb72MzDqfCf3B0Wc47qaFmoZUrhqa0rJx630JOmmrryUMsTESmIFqalXYcR9j0xtcCqHvuGXGpuWlE+IPQyS+M1LK0YHHq5UlhWrR8cenJTHytiyWp9TYqIhKswEqa+B4eeMEWBpf2PDLnU3PRut88RC7kqrC/pqe+Vk0BL1wynKBrup7euvoSla/cOtUwRkYJImD7e6yvEQh61vDZayqZeI0ItM1f9u+/x1EWKQyuvOlLKU/2+HFp5Urg2b+/F6g17hFpmPF7Exyvax2dXRNpOQSRM8aIyXtjt84Q19LsG+M9eXwmptNz3SadhLO0wmHhISacBz/Q7KZSypPBNn30aNbXhjHerrStl1jtfJu6ioZQnItKgIBImgBmH/ZZKa/nmxIBVRRW8fdD3WlxWPvnDPldSF8Lg+apIOXcPPp9NJd1DiErag3c+PpwV64ZQH2t5krO9ujMz3vxaCFGJiOysYBKm+pLO3DXmpy1uZaoF/nbkzRApmF2TlkWd9uKeQd+kKtL8K/1aK2Fxxz15aI8zQoxMCp/xt39dQV19GfEW3CxXVR3hrmeupC5WGl5oIiK+gsoKlg45gbsP+B9qIePnVseAKuBPh17VbsYuJbtv0Nd5ut+XqG5G0lQTKWVph0H8ZOQtxE3dIZKZTdt24+aH/0hNbQdi8cwOS3EHNXWl/O3fV7Fkje6OE5HWUVAJE8DcA77FzYdexUaLpt3aVAOsjJbxx6NvY/mgya0ZXm4z48/DLuGG4ZdRGS2nzoIf0xXHqI6U8q++x/O90XdQWdSxDQKVQrRi3VB+/8/bWL52WNpjmmrqStm4pQ83PXQ9c5cc3MoRikh7VhAPrky2fNBkfrv74Yx79UomLJ9Fud/e1NBQHwfq8AYnb4wU8589T2DO6B/hIgW5OzI2ffcv8laPMZyy+E4mr3yCuEUojtdS4uoAiBGhOlpOkavjnW6juWfwt5nb5YAsRy2FYMPWPlz/wE18btjzTBp9L907rybuIt4Twf17Empqy3AY1bUdeH7O13jp/eOJxcN/eK2ISKKCzRBiJRW8cPjveSEep//SfzNg5cuMX/w0Dvi46zCW9dyfpf2PYO3u47Idak5aX9qL/x3+Y24fejF7b3mfYVs+pH/lUiIuzvrSXizovA9zu4zQ4G4JnSPCnAUTmbNgIr27LmPgbvPo33sBIxc+iquCZ/tdwLI1w1ixbiihfwmiiEgjCjZh+kwkwvJBk1k+aDK/XPw0AJOOuzfLQeWP2mgZ73YbzbvdRgfPLBKytZsGsHbTAGbPn0T/G58E4NWLv5jlqESkPSq4MUwiIiIiYVPCJCIiIhJACZOIiIhIACVMIiIiIgGUMImIiIgEUMIkIiIiEkAJk4iIiEgAJUwiIiIiAZQwiYiIiARQwiQiIiISQAmTiIiISAAlTCIiIiIBlDCJiIiIBFDCJCIiIhJACZOIiIhIACVMIiIiIgGKWqPQvhVDOX+f62D+qtYovsXG52pco57Y8Y8f44vD+2YpGhEREWkQ2MJkZgPMbIaZfWhmH5jZ1LYITERERCRXpNPCVA9c4px708w6AXPM7Dnn3IetHJtI2qbOP5+po0btmDD//OwFk6d22n93T2D6OTOzFUpeuWFDJ5i24//pjM5aLHlr2o4/pzOaiQtmZy0UkcYEJkzOuVXAKv/vrWY2F+gHKGFqA9Pv1cE3HTud7CUUN1zcKdsh7OQk/3euxZV4spdw6LjXfNp3rSejQd9mNggYCbyW4rXzzGy2mc2urN8cUngiIiIi2Zd2wmRmHYGHgO8557Ykv+6cu805N9o5N7qiqEuYMYqIiIhkVVp3yZlZMV6y9A/n3MOtG5Ikmni6+vLTojFLocu1utdt+nkATJx4W5Yj2ZnGLIUv1+perkvshtO+y1y63Zjp3CVnwF+Buc65P7YwLhEREZG8k04L0zjgLOA9M3vbn3a5c+7pdFdy1v/t04zQWsFQ71fOxAP8/ZS52Q5BREREAqRzl9yLgLVBLCIiIiI5SV+NIiIiIhJACZOIiIhIACVMIiIiIgGUMImIiIgEUMIkIiIiEkAJk4iIiEgAJUwiIiIiAZQwiYiIiARQwiQiIiISQAmTiIiISAAlTCIiIiIBlDCJiIiIBFDCJCIiIhJACZOIiIhIACVMIiIiIgGKsh1AW4jX1bF1wQLmATFg41NP0Wn4cDoOHoxFo9kOT0QaETFH/741DBpQTfde+xCvqWdIt0oWLy8nFrNsh5fzyorKOHC3AxnafSjF0WI2V2/m7dVvs2jTomyHJpJ3Cjph2vjWWyz8y19YM2MG0ZISDHAAl1+Ocw4Xi9Hv+OMZ8s1v0mmvvbIcrYg0GNivmq8c+ylHHboR54x4HMrcYRB3XBv9mJJix2tvd+L+J3szd2GHbIebc74w5AtcOu5Sxg8cT2VdJRGLYGbE4jGKIkXUx+u5bc5t3PT6TSzbsizb4YrkhYJMmGo3beLdK65g7QsvEKuuBueor6vbMcP27Z/9ueyRR1jx5JMM/NrX2PfHPyZaVpaFiEUEoLg4zrdOXcVxR66nqMhRFAX/MgcoBqADcQAOHbWF0SO28sY7nbnu9v5s3V6Qh7OMDOwykHu/fC8jdhtBp9JOAHSJdkk578UHX8x3x3yXaTOnce0r1xJ38bYMVSTvFNwYpm2LFjHjmGNYM2MGsaoqcK7pBWIx4tXVLL3/fmZNmULN+vVtE6iI7KRLp3puvXoBxx25nrLShmSpcZEIlJU6Dh65hTv+MI/+favbJtAcNW7AON7/zvuM6Tfms2SpKaVFpVQUV/DzI37O82c/T3lReRtEKZK/Ciphqlq5khdPPpnajRuJ19ZmtGy8uprK5ct58eSTqd+2rZUiFJFUystiXD/tI/r0rqGsNOAiJ0lJsaNzxxg3XLmQXj0y+9wXipF9RvLsmc/SqbQTxdHijJbtWNKRMf3G8MyZzxCxgjoliISqYD4dzjnmTJ1K/datwa1KjZVRX0/1mjW898tfhhydiDTlgrNX0Kt7HcXN7FWLRKCiPMZPL1rCji689qGsqIzHTn2MjiUdm11GeXE5o/qO4pKxl4QYmUhhKZiEafmjj7Jl3jxcLNaicuI1Nax65hk2zJkTUmQi0pR999rOhEM2UVrSskSnqAgGD6hm4viNIUWWH35+xM/pXt69xeV0LOnItAnTGNhlYAhRiRSegkiYnHMsuOkmb8xSCGLV1Sy45ZZQyhKRpp1+4hpKisNpFSovi3Pml9bQXlqZSqOlfPfz36VDSTh3CkYswoWfvzCUskQKTUEkTJs/+ICadevCK9A51r/6KrUb29eVqkhb69ShnpH7byMS4pGoe9d69hoUzsVTrjth+AmhlldWVMZ5o84LtUyRQlEQCdPGt95qcVdcskhpKZveey/UMkVkZ8P3rKS2NtwHUEYijn33qgy1zFw1YdCEFo1dSqUoUsSe3fYMtUyRQlAYCdObbxKvqQm1zFhVFVvmzg21TBHZ2ZA9qiktDff5P6Uljn332h48YwEY239s6He21cfrOajPQaGWKVIICuJJb63Rdebq66nZsCH0ckVkh44d6pt9Z1xTPl//Hn+Y/uvwC05h40ttspqU9v566odStkQ0EqVrWdfQyxXJdwXRwmTFmT13JF3RkpJWKVdEPPX11tyngDQpXhNuF32ucvX14ZfpHHWxuuAZRdqZgmhh6rz33qydNQvi4TXtRysq6LCn+vFFWtOKNaVUVUeoKA/vsxuLwVNVn+fOiSeGVmZTpg8b3SbrSeWxunmcwLBQy4y7OAs3LAy1TJFCUBAtTN0OPJCiiorQy+26336hlykiOyz4pAILd8w31TUR5n/cPr6Qd+bimVTXh/uVMBXFFbyz5p1QyxQpBAWRMPUcO5Z4yE3TxR070nHo0FDLFJGdLV1ZyrbKcA9D0ajjrQ/CvXMsVz02/zFcyH2aLy97mcq69nGXoUgmCiJhKurQgf4nnogVhdPDGCkrY89vfhML8+EwIpKC8cCTvamuCaeZqa4eZrzclarqgG/uLRCfbPyE2StnEw9pOMLWmq38/uXfh1KWSKEpmIxg+NSpREIapF3cpQt7nH56KGWJSNOeer4HW7eFc7FTVxfh7gf7hlJWvrjomYuojrW8W64uVseHn37I0x89HUJUIoWnYBKmst69GfGrXxEtL29ROZGyMkbfeCNFLSxHRNJTWxfhqpv2aHErU3W1ceOd/Vi/qXXums1V76x5h2tfvpbttS179lR1fTWnPnQqrp18rYxIpgomYQLof+KJ7PmtbzU7aYqUlTHiqqvoPmpUyJGJSFM+/KgD193ev9lJU3W18eDTvfjPSy3/Etp8dOXMK3l8/uNsq93WrOW3125nyj+nsHjT4nADEykgBZUwAew9dSr7XXEF0bIyLJreOAYrLqaoUydG33QTA046qXUDFJGUnn+5O7+6YRDbtkeorUsvcaqPQXWN8ed7dufuh9pXV1wih+OMh8/g+levp7KukrhLb0xTZV0ly7csZ8LdE3hhyQutG6RIniu4hAlgj1NPZcKzz9Lr8MOJlJQQKStLOV+0vJxIaSn9pkzh6OefZ7cjj2zjSEUk0evvdObsH+zDjJe7UlNrVFWnTpyqa4zaWmPOu5349qXDeWpGzzaONPc4HD+b8TPG3TGOV5a9QlVdVcpHDsRdnC01W9hWu41bXr+FYTcNY/bK2VmIWCS/FMSDK1Op6N+fg//yF6rXrmXVs8+y/vXX2TJ/PvGaGqLl5XQ94AB6jBlD38mTKe7cOdvhiohv67Yi/nDbQP50Tz8O+/wmRuyzjb0GV1FeGqe2zvhkWTnvze3Ii290aXfjldLx9uq3GX/neIZ2H8qJw0/kiD2OYJ9e+1AUKWJz9WZeWf4Ks5bM4tF5j4b+DCeRQlawCVODst69GXz22Qw+++xshyIiGdheGeXZWT14dlaPbIeSlxZuWMi1r1zLta9cm+1QRApCQXbJiYiIiIRJCZOIiIhIACVMIiIiIgGUMImIiIgEUMIkIiIiEkAJk4iIiEgAJUwiIiIiAZQwiYiIiARQwiQiIiISQAmTiIiISAAlTCIiIiIBlDCJiIiIBFDCJCIiIhJACZOIiIhIACVMIiIiIgGUMImIiIgEKGqLlfz9lLltsRoRERGRVhHYwmRmZWb2upm9Y2YfmNkv2iIwERERkVyRTgtTDXCUc26bmRUDL5rZM865V1s5NhEREZGcEJgwOeccsM3/t9j/ca0ZlOww/d7R2Q4hL0wdNSrbIRQc1b00Tct2AIVHda/5tO9aT1qDvs0samZvA2uB55xzr6WY5zwzm21msyvrN4ccpoiIiEj2pJUwOedizrmDgP7AGDPbP8U8tznnRjvnRlcUdQk5TBEREZHsyeguOefcJjObAUwG3m+dkCTRxNNnZzuE/DD//GxHUHCm3rg12yHkhRs2dMp2CAVHx73MJHbDad9lLt1uzMCEycx6AXV+slQOTAJ+17LwRMJ1w/BbddBoocT9p2QpfVO7b+WGi3ckTap7mdNnV/JBOi1MfYG7zSyK14V3v3PuyaYWWFW5kGlzjlfFz5AOGiIiIrkpnbvk3gVGtkEsIiIiIjlJX40iIiIiEkAJk4iIiEgAJUwiIiIiAZQwiYiIiARQwiQiIiISQAmTiIiISAAlTCIiIiIBlDCJiIiIBFDCJCIiIhJACZOIiIhIACVMIiIiIgGUMImIiIgEUMIkIiIiEkAJk4iIiEgAJUwiIiIiAZQwiYiIiARQwiQiIiISQAmTiIiISAAlTCIiIiIBlDCJiIiIBFDCJCIiIhJACZOIiIhIgKJsByAikujVp6/mnf/eyvm/WbLLa9u3rOH5+y5m7Yp3qdr6KaUVXdl9z7EcOuVKuvUemoVoRaS9UAuTiOSN+tpKSiu6Mva4n3LSdx7h8C/9lo1rP+Lhm6dQU7kp2+GJSAFTC5OI5I0uPQdzzJm37jSt94CD+NtVI1n20SyGHnhiliITkUKnFiYRyWvlHboDEKuvy3IkIlLI1MIkInnHxePEXYztm1fxypO/olP3gQze7wvZDktECpgSJhHJO88/8H3ef+kOALr0GMyXLniMkrJOWY5KRAqZuuREJO98ftIPOeWSmRz39b9T3rEHj/7vSWzfsjbbYYlIAVPCJCJ5p3P3AfTZYxR7jTyJky54jJqqzbz739uyHZaIFDAlTCKS10rLO9Ol52A2r1+c7VBEpIApYRKRvFa1bR0b135Elx57ZDsUESlgGvQtIjknXl/HR289usv0zes+YeumFfQbMo6KTr3YvH4xb828hWhRCfsf+o22D1RE2g0lTCKSc2prtvL0nWftMv1L332cJfOf56M3H6K2Zhsdu/aj/9DxjJn8Ezp165eFSEWkvVDCJCI55ZDjLueQ4y5v9PWBw49sw2hERDwawyQiIiISQAmTiIiISAAlTCIiIiIBlDCJiIiIBFDCJCIiIhJACZOIiIhIACVMIiIiIgGUMImIiIgEUMIkIiIiEkAJk4iIiEgAJUwiIiIiAZQwiYiIiARQwiQiIiISQAmTiIiISAAlTCIiIiIBlDCJiIiIBFDCJCIiIhJACZOIiIhIACVMIiIiIgGUMImIiIgEUMIkIiIiEiDthMnMomb2lpk92ZoBiYiIiOSaTFqYpgJzWysQERERkVyVVsJkZv2BLwK3t244IiIiIrnHnHPBM5k9CPwG6AT80Dk3JWD+4EJFREREcsMc59zopmYIbGEysynAWufcnID5zjOz2WY2O8MgRURERHJaYAuTmf0GOAuoB8qAzsDDzrkzm1hGLUwiIiKSLwJbmNLqkvtsZrMJZNAlN/F0NTZlYvq9O94r7bvMJe6/qTduzWIk+emGizt99rfqX2b02W0Z7b+W0f5rGX//tbxLTkRERKS9K8pkZufcTGBmq0QiIiIikqPUwiQiIiISQAmTiIiISAAlTCIiIiIBlDCJiIiIBFDCJCIiIhJACZOIiIhIACVMIiIiIgGUMImIiIgEUMIkIiIiEkAJk4iIiEgAJUwiIiIiAZQwiYiIiARQwiQiIiISQAmTiIiISAAlTCIiIiIBlDCJiIiIBFDCJCIiIhJACZOIiIhIACVMIiIiIgGUMImIiIgEUMIkIiIiEkAJk4iIiEgAJUwiIXv16au59bI90pr3ydtP44aLO/HOC7e2clQiItISSphEsmTJ3P+watHr2Q5DRETSoIRJJAtisTpmPfxjxk75ebZDERGRNChhEsmCt2f+L0XF5ex38FnZDkVERNKghEmkjW3fsobX/3UNR3z5t1hEH0ERkXygo7VIG3vxsZ+xx95H02/o+GyHIiIiaVLCJNKGVi16jYVvP8r4k67KdigiIpKBomwHINKezHr4J+w/7huUlnWmpnLTZ9Pr66qoqdpMaXmX7AUnIiKNUsIk0oY2rv2INUtm8/bMW3aa/uJjP+OlJ6Zx8fWbshOYiIg0SQmTSBs64bz7cfHYTtMeuuk4DjriOwwZcUKWohIRkSBKmERaQby+jo/eenSX6f2GjqOiU69dpnftNYT+e2kQuIhIrlLCJNIKamu28vSduz5j6SsXPZ0yYRIRkdymhEkkZIccdzmHHHd52vNPvXFrK0YjIiJh0GMFRERERAIoYRIREREJoIRJREREJIASJhEREZEASphEREREAihhEhEREQmghElEREQkgBImERERkQBKmEREREQCKGESERERCaCESURERCSAEiYRERGRAEqYRERERAIoYRIREREJoIRJREREJIASJhEREZEASphEREREAihhEhEREQmghElEREQkgBImERERkQBKmEREREQCFKUzk5ktBrYCMaDeOTe6NYMSERERySVpJUy+I51z61otEhEREZEcpS45ERERkQDmnAueyWwRsBFwwK3OudsC5g8uVERERCQ3zAkabpRul9x459wKM+sNPGdm85xzLyTOYGbnAef5/9YA72ccrgD0BNT12Xzafy2j/dd82ncto/3XMtp/LTM8aIa0Wph2WsBsGrDNOfeHJuaZrYHhzaN91zLafy2j/dd82ncto/3XMtp/LZPO/gscw2RmHcysU8PfwDGo9UhERETakXS65HYDHjGzhvnvdc4926pRiYiIiOSQwITJOfcJcGCG5TY5KFyapH3XMtp/LaP913zady2j/dcy2n8tE7j/Mh7DJCIiItLe6DlMIiIiIgFCTZjMbLKZzTezhWb2kzDLLnRmdoeZrTUzDahvBjMbYGYzzOxDM/vAzKZmO6Z8YWZlZva6mb3j77tfZDumfGRmUTN7y8yezHYs+cbMFpvZe2b2tpnNznY8+cTMuprZg2Y2z8zmmtnYbMeUL8xsuF/nGn62mNn3Gp0/rC45M4sCC4BJwHLgDeA059yHoaygwJnZ4cA24G/Ouf2zHU++MbO+QF/n3Jv+XZ1zgJNU/4KZd0dHB+fcNjMrBl4EpjrnXs1yaHnFzH4AjAY6O+emZDuefOJ/X+loff1W5szsbuC/zrnbzawEqHDObcpyWHnHz2FWAAc755akmifMFqYxwELn3CfOuVrgPuDEEMsvaP6DQDdkO4585Zxb5Zx70/97KzAX6JfdqPKD82zz/y32fzS4MQNm1h/4InB7tmOR9sPMugCHA38FcM7VKllqtqOBjxtLliDchKkfsCzh/+XohCVZYGaDgJHAa1kOJW/43UlvA2uB55xz2neZuR74MRDPchz5ygH/NrM5/rdGSHoGA58Cd/rdwbf7z0uUzJ0K/LOpGTToWwqKmXUEHgK+55zbku148oVzLuacOwjoD4wxM3ULp8nMpgBrnXNzsh1LHhvvnPsccCzwXX+IggQrAj4H/Mk5NxLYDmj8cIb8rswTgAeami/MhGkFMCDh//7+NJE24Y+/eQj4h3Pu4WzHk4/85vwZwOQsh5JPxgEn+ONw7gOOMrN7shtSfnHOrfB/rwUewRviIcGWA8sTWoQfxEugJDPHAm8659Y0NVOYCdMbwF5mNtjP1k4FHg+xfJFG+QOX/wrMdc79Mdvx5BMz62VmXf2/y/Fu3JiX1aDyiHPuMudcf+fcILzj3vPOuTOzHFbe0NdvNZ9zbjWwzMwavjj2aEA3umTuNAK64yC9r0ZJi3Ou3swuBP4FRIE7nHMfhFV+oTOzfwITgJ5mthy40jn31+xGlVfGAWcB7/ljcQAud849nb2Q8kZf4G7/LpEIcL9zTrfGS1vR12+1zEXAP/yGik+Ar2c5nrziJ+mTgPMD59WTvkVERESapkHfIiIiIgGUMImIiIgEUMIkIiIiEkAJk4iIiEgAJUwiIiIiAZQwiYiIiARQwiQiIiISQAmTiIiISID/B3AH/qLhpUPPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "all_locations = np.vstack(history_of_locs).astype(float) # create a matrix containing the agent's Y/X locations over time (each coordinate in one row of the matrix)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6)) \n",
    "\n",
    "# create the grid visualization\n",
    "X, Y = np.meshgrid(np.arange(grid_dims[1]+1), np.arange(grid_dims[0]+1))\n",
    "h = ax.pcolormesh(X, Y, np.ones(grid_dims), edgecolors='k', vmin = 0, vmax = 30, linewidth=3, cmap = 'coolwarm')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# get generative process global parameters (the locations of the Cues, the reward condition, etc.)\n",
    "cue1_loc, cue2_loc, reward_condition = my_env.cue1_loc, my_env.cue2_loc, my_env.reward_condition\n",
    "reward_top = ax.add_patch(patches.Rectangle((reward_locations[0][1],reward_locations[0][0]),1.0,1.0,linewidth=5,edgecolor=[0.5, 0.5, 0.5],facecolor='none'))\n",
    "reward_bottom = ax.add_patch(patches.Rectangle((reward_locations[1][1],reward_locations[1][0]),1.0,1.0,linewidth=5,edgecolor=[0.5, 0.5, 0.5],facecolor='none'))\n",
    "reward_loc = reward_locations[0] if reward_condition == \"LEFT\" else reward_locations[1]\n",
    "\n",
    "if reward_condition == \"LEFT\":\n",
    "    reward_top.set_edgecolor('g')\n",
    "    reward_top.set_facecolor('g')\n",
    "    reward_bottom.set_edgecolor([0.7, 0.2, 0.2])\n",
    "    reward_bottom.set_facecolor([0.7, 0.2, 0.2])\n",
    "elif reward_condition == \"RIGHT\":\n",
    "    reward_bottom.set_edgecolor('g')\n",
    "    reward_bottom.set_facecolor('g')\n",
    "    reward_top.set_edgecolor([0.7, 0.2, 0.2])\n",
    "    reward_top.set_facecolor([0.7, 0.2, 0.2])\n",
    "reward_top.set_zorder(1)\n",
    "reward_bottom.set_zorder(1)\n",
    "\n",
    "text_offsets = [0.4, 0.6]\n",
    "cue_grid = np.ones(grid_dims)\n",
    "cue_grid[cue1_loc[0],cue1_loc[1]] = 15.0\n",
    "for ii, loc_ii in enumerate(cue2_locations):\n",
    "  row_coord, column_coord = loc_ii\n",
    "  cue_grid[row_coord, column_coord] = 5.0\n",
    "  ax.text(column_coord+text_offsets[0], row_coord+text_offsets[1], cue2_loc_names[ii], fontsize = 15, color='k')\n",
    "  \n",
    "h.set_array(cue_grid.ravel())\n",
    "\n",
    "cue1_rect = ax.add_patch(patches.Rectangle((cue1_loc[1],cue1_loc[0]),1.0,1.0,linewidth=8,edgecolor=[0.5, 0.2, 0.7],facecolor='none'))\n",
    "cue2_rect = ax.add_patch(patches.Rectangle((cue2_loc[1],cue2_loc[0]),1.0,1.0,linewidth=8,edgecolor=[0.5, 0.2, 0.7],facecolor='none'))\n",
    "\n",
    "ax.plot(all_locations[:,1]+0.5,all_locations[:,0]+0.5, 'r', zorder = 2)\n",
    "\n",
    "temporal_colormap = cm.hot(np.linspace(0,1,T+1))\n",
    "dots = ax.scatter(all_locations[:,1]+0.5,all_locations[:,0]+0.5, 450, c = temporal_colormap, zorder=3)\n",
    "\n",
    "ax.set_title(f\"Cue 1 located at {cue2_loc}, Cue 2 located at {cue2_loc}, Cheese on {reward_condition}\", fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24ee14d9f6452059a99d44b6cbd71d1bb479b0539b0360a6a17428ecea9f0810"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('pymdp_env2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
